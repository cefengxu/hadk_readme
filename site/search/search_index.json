{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"HADK Development Documentation","text":"<p>Welcome to the HADK framework development documentation!</p>"},{"location":"#what-it-is","title":"What It Is","text":"<p>HADK (Hybrid Agent Development Kit) is a C++-based, cross-platform framework for building intelligent agents. Built on computational graph principles, it offers a modular architecture with rich functional nodes and flexible orchestration. Developers can quickly create agents with advanced reasoning, tool integration, and multimodal capabilities that run seamlessly across Windows, Linux, and Android.</p>"},{"location":"#its-advantages","title":"Its Advantages","text":"<ul> <li>Cross-platform: Write once, run on Windows, Linux, and Android with a unified API</li> <li>Node-based Architecture: Computational graph-based orchestration with conditional routing, nested flows, and loops</li> <li>Type Safety: Compile-time type checking via C++ templates to catch errors early</li> <li>High Performance: Native compilation with zero-copy optimization and concurrent processing</li> <li>Tool Ecosystem: Integrate local tools, remote servers (MCP/SSE), or build your own</li> <li>Modular: Clean separation of concerns for easy extension and reuse</li> </ul>"},{"location":"#development-environment","title":"Development Environment","text":"<ul> <li>C++ Compiler: Supports C++17 or higher</li> <li>CMake: Version 3.24 or higher</li> <li>Operating System: Windows 10+, Linux (Ubuntu 20.04+), Android (API 21+)</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#basic-concepts","title":"Basic Concepts","text":"<ul> <li>Chat Node - Chat node integrated with large language models</li> <li>Tool Node - Tool management node</li> <li>Custom Node - User-defined node for custom logic</li> <li>CE Node - Context engine node for managing conversation history</li> <li>Chain and Flow - Workflow management</li> <li>Route - Routing node</li> </ul>"},{"location":"#application-development","title":"Application Development","text":"<ul> <li>Single Node Agent - Single node agent development example</li> <li>Double Node Agent - Two node agent development example</li> <li>Triple Node Agent - Three node agent development example</li> <li>Agent with Specified Tools - Conditional routing agent with tool node development example</li> <li>Inja Template Formatting - Inja template engine tutorial</li> <li>Agent via CE Node - Context compression agent development example</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Please select the chapter you're interested in from the left navigation bar to start reading.</p>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<p>Thanks to the following open-source projects for their support:</p> <ul> <li>cpr - HTTP client</li> <li>nlohmann/json - JSON library</li> <li>spdlog - Logging library</li> <li>yaml-cpp - YAML parsing library</li> <li>inja - Template engine</li> </ul>"},{"location":"#contact","title":"Contact","text":"<ul> <li>liusong9@lenovo.com</li> <li>zengjl1@lenovo.com</li> <li>moutz1@lenovo.com</li> <li>xufeng8@lenovo.com</li> </ul>"},{"location":"1-1%20Basic%20Concepts%20Chat%20Node/","title":"Chat Node","text":"<p>Chat Node is a node component that integrates large language models (LLM) and function calling capabilities, supporting both online and offline model invocation. Its interface strictly follows the OpenAI Chat Completion API specification.</p>"},{"location":"1-1%20Basic%20Concepts%20Chat%20Node/#building-a-chat-node","title":"Building a Chat Node","text":"<p>Build a chat node in the following way, allowing parameter configuration for model invocation:</p> <pre><code>chat_node::chat_node_settings s_generate;\ns_generate.model = \"gpt-4.1\";\ns_generate.temperature = 0.7;\ns_generate.top_p = 0.95;\ns_generate.max_tokens = 4096;\ns_generate.tool_choice = \"none\";\nconst auto generate_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_generate);\n</code></pre>"},{"location":"1-1%20Basic%20Concepts%20Chat%20Node/#chat-node-input-and-output","title":"Chat Node Input and Output","text":"<p>The default data type for both input and output is <code>std::string</code> (for custom data types, please refer to <code>Advanced Usage</code>).</p>"},{"location":"1-1%20Basic%20Concepts%20Chat%20Node/#input-format","title":"Input Format","text":"<p>The input data structure strictly follows the OpenAI Chat Completion API specification, with the following format:</p> <pre><code>[\n  {\"role\":\"system\",\"content\":\"you are a helpful assistant\"},\n  {\"role\":\"user\",\"content\":\"who are you?\"}\n]\n</code></pre> <p>It also supports multimodal input (if the model supports it):</p> <pre><code>[\n    {\n        \"content\": \"You are a helpful assistant with multiple tools.\",\n        \"role\": \"system\"\n    },\n    {\n        \"content\": [\n            {\n                \"text\": \"what is this?\",\n                \"type\": \"text\"\n            },\n            {\n                \"image_url\": {\n                    \"detail\": \"low\",\n                    \"url\": \"https://1.bp.blogspot.com/529.jpg\"\n                },\n                \"type\": \"image_url\"\n            }\n        ],\n        \"role\": \"user\"\n    }\n]\n</code></pre> <p>Alternatively, images can be represented in base64 format:</p> <pre><code>[\n    {\n        \"content\": \"You are a helpful assistant with multiple tools.\",\n        \"role\": \"system\"\n    },\n    {\n        \"content\": [\n            {\n                \"text\": \"what is this?\",\n                \"type\": \"text\"\n            },\n            {\n                \"image_url\": {\n                    \"detail\": \"low\",\n                    \"url\": \"data:image/png;base64,dfadfnakjenqlkmdcklasjdflkadslfkadsokfqmldf\"\n                },\n                \"type\": \"image_url\"\n            }\n        ],\n        \"role\": \"user\"\n    }\n]\n</code></pre>"},{"location":"1-1%20Basic%20Concepts%20Chat%20Node/#output-format","title":"Output Format","text":"<p>The output data structure strictly follows the OpenAI Chat Completion API specification, with the following format:</p> <pre><code>[\n  {\"role\":\"system\",\"content\":\"you are a helpful assistant\"},\n  {\"role\":\"user\",\"content\":\"who are you?\"},\n  {\"role\":\"assistant\",\"content\":\"my name is bob.\"}\n]\n</code></pre>"},{"location":"1-2%20Basic%20Concepts%20Tool%20Node/","title":"Tool Node","text":"<p>Tool Node is a tool management node that supports the following features:</p> <ul> <li>Tool Registration and Management: Supports registration, execution, and destruction of MCP (Model Context Protocol) tools (SSE/STDIO) and local tools</li> <li>Function Call Integration: Can serve as the foundation for Chat Node's Function Call, or execute independently</li> <li>Custom Extensions: Supports user-defined local functions registered to the Tool Node</li> </ul>"},{"location":"1-2%20Basic%20Concepts%20Tool%20Node/#registering-tools","title":"Registering Tools","text":""},{"location":"1-2%20Basic%20Concepts%20Tool%20Node/#registering-local-tools","title":"Registering Local Tools","text":"<p>For local tool development specifications, please refer to <code>Local Tool Development Specifications</code>.</p> <pre><code>common_tools::tools::add_function_call(search_news_tool,\n    R\"({\"type\":\"function\",\"function\":{\"name\":\"search_news\",\"description\":\"Search for the latest news information using keywords\",\"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search keywords\",\"minLength\":1},\"time_range\":{\"type\":\"string\",\"enum\":[\"day\",\"week\"]},\"country\":{\"type\":\"string\",\"enum\":[\"china\",\"usa\",\"japan\"]}},\"required\":[\"query\"]}}})\"\n);\n</code></pre>"},{"location":"1-2%20Basic%20Concepts%20Tool%20Node/#registering-mcp-tools","title":"Registering MCP Tools","text":"<pre><code>const auto r1 = common_tools::tools::add_server(\n    R\"({\"WeatherServer\":{\"url\":\"http://18.119.131.41:8006\",\"sse_endpoint\":\"/sse\"}})\"\n);\n</code></pre>"},{"location":"1-2%20Basic%20Concepts%20Tool%20Node/#getting-tool-status-mcp-tools-only","title":"Getting Tool Status (MCP Tools Only)","text":"<p>The function to get the initialization status of MCP tools is as follows:</p> <pre><code>int status = common_tools::tools::get_server_init_status(std::string(name));\n</code></pre> <p>Parameter Description: - <code>name</code>: The unique identifier name of the tool (case-sensitive)</p> <p>Return Value: - <code>1</code>: Initialization successful - <code>2</code>: Initialization failed - <code>0</code>: Initialization in progress - <code>-1</code>: Unknown status</p>"},{"location":"1-2%20Basic%20Concepts%20Tool%20Node/#closing-tools-mcp-tools-only","title":"Closing Tools (MCP Tools Only)","text":"<p>The function to close all MCP tools is as follows:</p> <pre><code>common_tools::tools::shutdown_all_servers();\n</code></pre>"},{"location":"1-2%20Basic%20Concepts%20Tool%20Node/#executing-tools","title":"Executing Tools","text":""},{"location":"1-2%20Basic%20Concepts%20Tool%20Node/#automatic-invocation-via-chat-node","title":"Automatic Invocation via Chat Node","text":"<p>Tools can serve as Chat Node's Function Call functions, automatically judged and invoked by the model. By configuring as follows, Chat Node will have tool invocation capabilities:</p> <pre><code>chat_node::chat_node_settings s;\ns.model = \"gpt-4o-mini\";\ns.temperature = 0.7;\ns.max_tokens = 4096;\ns.tool_choice = \"auto\";  // Enable automatic tool selection\ns.tools_json = common_tools::tools::get_all_tools_json();  // Get all registered tools\nconst auto node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s);\n</code></pre>"},{"location":"1-2%20Basic%20Concepts%20Tool%20Node/#manually-invoking-a-specified-tool","title":"Manually Invoking a Specified Tool","text":"<p>Manually execute a specified tool in the following way:</p> <pre><code>std::string ws_out = common_tools::tools::call_tool(\"search_web2\", ws_in_json.dump());\n</code></pre>"},{"location":"1-2%20Basic%20Concepts%20Tool%20Node/#tool-input-format","title":"Tool Input Format","text":"<p>Tool input parameters strictly follow the OpenAI Chat Completion API's Function Call parameter format, passed as <code>std::string</code> type. The input is a JSON-formatted parameter string:</p> <pre><code>{\n  \"query\": \"Search keywords\",\n  \"time_range\": \"day\",\n  \"country\": \"china\"\n}\n</code></pre> <p>Example Code:</p> <pre><code>nlohmann::json params;\nparams[\"query\"] = \"Latest tech news\";\nparams[\"time_range\"] = \"day\";\nparams[\"country\"] = \"china\";\nstd::string arguments = params.dump();\n\nstd::string result = common_tools::tools::call_tool(\"search_news\", arguments);\n</code></pre> <p>For local tool development specifications, please refer to <code>Local Tool Development Specifications</code>.</p>"},{"location":"1-2%20Basic%20Concepts%20Tool%20Node/#tool-output-format","title":"Tool Output Format","text":"<p>Tool output results strictly follow the OpenAI Chat Completion API's Function Call response format, returned as <code>std::string</code> type. The output is in JSON format:</p> <pre><code>{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"Tool execution result content\"\n    }\n  ],\n  \"isError\": false\n}\n</code></pre> <p>Field Description: - <code>content</code>: Result content array, each element contains <code>type</code> and <code>text</code> fields - <code>isError</code>: Boolean value indicating whether an error occurred</p> <p>Example Code:</p> <pre><code>std::string result = common_tools::tools::call_tool(\"search_news\", arguments);\nnlohmann::json result_json = nlohmann::json::parse(result);\n\nif (!result_json[\"isError\"].get&lt;bool&gt;()) {\n    std::string text = result_json[\"content\"][0][\"text\"].get&lt;std::string&gt;();\n    // Process result\n}\n</code></pre> <p>For local tool development specifications, please refer to <code>Local Tool Development Specifications</code>.</p>"},{"location":"1-3%20Basic%20Concepts%20DIY%20Node/","title":"Custom Node","text":""},{"location":"1-3%20Basic%20Concepts%20DIY%20Node/#building-a-custom-node","title":"Building a Custom Node","text":"<p>You can build custom processing nodes using <code>OneFuncNode</code> to implement arbitrary business logic. Nodes define processing functions through Lambda expressions and support custom input and output types.</p>"},{"location":"1-3%20Basic%20Concepts%20DIY%20Node/#basic-usage","title":"Basic Usage","text":"<pre><code>auto custom_node = std::make_shared&lt;nodeflow::OneFuncNode&lt;std::string, std::string&gt;&gt;(\n    [&amp;](const std::string&amp; input) -&gt; std::string {\n        // Custom processing logic\n        std::string processed = process_input(input);\n        return processed;\n    }\n);\n</code></pre>"},{"location":"1-3%20Basic%20Concepts%20DIY%20Node/#practical-example","title":"Practical Example","text":"<p>The following example shows how to build a text polishing prompt generation node:</p> <pre><code>auto polish_prompt_node = std::make_shared&lt;nodeflow::OneFuncNode&lt;std::string, std::string&gt;&gt;(\n    [&amp;](const std::string&amp; draft) -&gt; std::string {\n        std::string polish_prompt = \n            \"Please rewrite the following draft to make it more friendly and engaging:\\n\\n\" +\n            draft + \"\\n\\n\"\n            \"Rewriting requirements:\\n\"\n            \"- The tone should be natural, like chatting, warm and infectious\\n\"\n            \"- You can add some rhetorical questions to guide readers to think\\n\"\n            \"- Appropriately add metaphors or analogies to make the content more vivid\\n\"\n            \"- The opening should catch the eye, and the ending should be powerful and memorable\\n\"\n            \"Final language: English.\\n\";\n\n        return polish_prompt;\n    }\n);\n</code></pre> <p>Notes: - <code>OneFuncNode&lt;IN, OUT&gt;</code>: Template parameters specify input and output types respectively - Lambda expression: Receives input parameters and returns processed output - Type safety: Compile-time checking of input and output type matching</p>"},{"location":"1-4%20Basic%20Concepts%20CE%20Node/","title":"CE Node","text":"<p>CE Node\uff08Context Engine Node\uff09\u662f\u4e00\u4e2a\u4e0a\u4e0b\u6587\u5f15\u64ce\u8282\u70b9\u7ec4\u4ef6\uff0c\u7528\u4e8e\u7ba1\u7406\u548c\u538b\u7f29\u5bf9\u8bdd\u5386\u53f2\u8bb0\u5f55\u3002\u5b83\u652f\u6301\u4e24\u79cd\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\uff1a\u88c1\u526a\uff08Trimming\uff09\u548c\u6458\u8981\uff08Summarizing\uff09\uff0c\u53ef\u4ee5\u6709\u6548\u63a7\u5236\u5bf9\u8bdd\u5386\u53f2\u7684\u957f\u5ea6\uff0c\u907f\u514d\u8d85\u51fa\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u3002</p>"},{"location":"1-4%20Basic%20Concepts%20CE%20Node/#building-a-ce-node","title":"Building a CE Node","text":"<p>\u6784\u5efa\u4e00\u4e2a CE \u8282\u70b9\u7684\u65b9\u5f0f\u5982\u4e0b\uff0c\u5141\u8bb8\u914d\u7f6e\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\u548c\u76f8\u5173\u53c2\u6570\uff1a</p> <pre><code>ce_node::ce_node_settings s_ce;\ns_ce.strategy = ContextStrategy::SUMMARIZING;\ns_ce.context_limit = 3; // \u89e6\u53d1\u538b\u7f29\u9608\u503c\uff0c\u5386\u53f2\u8bb0\u5f55\u8f6e\u6570\ns_ce.keep_last_n_turns = 1; // \u4fdd\u7559\u6700\u8fd1\u539f\u59cb\u6d88\u606f\u8f6e\u6570\ns_ce.tool_trim_limit = 600; // \u5de5\u5177\u7ed3\u679c\u5728\u5386\u53f2\u6d88\u606f\u4e2d\u4e0d\u662f\u5f88\u91cd\u8981\uff0c\u6240\u4ee5\u5de5\u5177\u7ed3\u679c\u7684\u524d600\u4e2a\u5b57\u7b26\u4f1a\u4fdd\u7559\ns_ce.summarizer_model = \"gpt-4o-mini\";\ns_ce.summarizer_max_tokens = 400;\nconst auto ce_node = std::make_shared&lt;ce_node::CeNode&lt;std::string, std::string&gt;&gt;(s_ce);\n</code></pre>"},{"location":"1-4%20Basic%20Concepts%20CE%20Node/#context-management-strategies","title":"Context Management Strategies","text":"<p>CE Node \u652f\u6301\u4e24\u79cd\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\uff1a</p>"},{"location":"1-4%20Basic%20Concepts%20CE%20Node/#trimming-strategy","title":"TRIMMING Strategy","text":"<p>\u88c1\u526a\u7b56\u7565\u76f4\u63a5\u5220\u9664\u8d85\u51fa\u9650\u5236\u7684\u5386\u53f2\u6d88\u606f\uff0c\u4fdd\u7559\u6700\u8fd1\u7684 <code>max_turns</code> \u8f6e\u5bf9\u8bdd\u3002</p> <pre><code>ce_node::ce_node_settings s_ce;\ns_ce.strategy = ContextStrategy::TRIMMING;\ns_ce.max_turns = 3; // \u5386\u53f2\u8bb0\u5f55\u6700\u5927\u4fdd\u7559\u8f6e\u6570\nconst auto ce_node = std::make_shared&lt;ce_node::CeNode&lt;std::string, std::string&gt;&gt;(s_ce);\n</code></pre>"},{"location":"1-4%20Basic%20Concepts%20CE%20Node/#summarizing-strategy","title":"SUMMARIZING Strategy","text":"<p>\u6458\u8981\u7b56\u7565\u4f7f\u7528 LLM \u5c06\u65e7\u7684\u5386\u53f2\u6d88\u606f\u538b\u7f29\u4e3a\u6458\u8981\uff0c\u4fdd\u7559\u6700\u8fd1 <code>keep_last_n_turns</code> \u8f6e\u7684\u539f\u59cb\u6d88\u606f\u3002\u5f53\u5386\u53f2\u8bb0\u5f55\u8f6e\u6570\u8d85\u8fc7 <code>context_limit</code> \u65f6\uff0c\u4f1a\u89e6\u53d1\u6458\u8981\u538b\u7f29\u3002</p> <pre><code>ce_node::ce_node_settings s_ce;\ns_ce.strategy = ContextStrategy::SUMMARIZING;\ns_ce.context_limit = 3; // \u89e6\u53d1\u538b\u7f29\u9608\u503c\uff0c\u5386\u53f2\u8bb0\u5f55\u8f6e\u6570\ns_ce.keep_last_n_turns = 1; // \u4fdd\u7559\u6700\u8fd1\u539f\u59cb\u6d88\u606f\u8f6e\u6570\ns_ce.tool_trim_limit = 600; // \u5de5\u5177\u7ed3\u679c\u4fdd\u7559\u7684\u5b57\u7b26\u6570\ns_ce.summarizer_model = \"gpt-4o-mini\";\ns_ce.summarizer_max_tokens = 400;\nconst auto ce_node = std::make_shared&lt;ce_node::CeNode&lt;std::string, std::string&gt;&gt;(s_ce);\n</code></pre>"},{"location":"1-4%20Basic%20Concepts%20CE%20Node/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"1-4%20Basic%20Concepts%20CE%20Node/#common-parameters","title":"Common Parameters","text":"<ul> <li><code>strategy</code>: \u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\uff0c\u53ef\u9009\u503c\u4e3a <code>ContextStrategy::TRIMMING</code> \u6216 <code>ContextStrategy::SUMMARIZING</code>\uff0c\u9ed8\u8ba4\u4e3a <code>SUMMARIZING</code></li> </ul>"},{"location":"1-4%20Basic%20Concepts%20CE%20Node/#trimming-strategy-parameters","title":"TRIMMING Strategy Parameters","text":"<ul> <li><code>max_turns</code>: \u5386\u53f2\u8bb0\u5f55\u6700\u5927\u4fdd\u7559\u8f6e\u6570\uff0c\u9ed8\u8ba4\u4e3a 8</li> </ul>"},{"location":"1-4%20Basic%20Concepts%20CE%20Node/#summarizing-strategy-parameters","title":"SUMMARIZING Strategy Parameters","text":"<ul> <li><code>context_limit</code>: \u89e6\u53d1\u538b\u7f29\u9608\u503c\uff0c\u5f53\u5386\u53f2\u8bb0\u5f55\u8f6e\u6570\u8d85\u8fc7\u6b64\u503c\u65f6\u89e6\u53d1\u6458\u8981\u538b\u7f29\uff0c\u9ed8\u8ba4\u4e3a 5</li> <li><code>keep_last_n_turns</code>: \u4fdd\u7559\u6700\u8fd1\u539f\u59cb\u6d88\u606f\u8f6e\u6570\uff0c\u8fd9\u4e9b\u6d88\u606f\u4e0d\u4f1a\u88ab\u538b\u7f29\uff0c\u9ed8\u8ba4\u4e3a 2</li> <li><code>tool_trim_limit</code>: \u5de5\u5177\u7ed3\u679c\u5728\u5386\u53f2\u6d88\u606f\u4e2d\u4fdd\u7559\u7684\u5b57\u7b26\u6570\uff0c\u9ed8\u8ba4\u4e3a 600</li> <li><code>summarizer_model</code>: \u7528\u4e8e\u6458\u8981\u7684\u6a21\u578b\u540d\u79f0\uff0c\u9ed8\u8ba4\u4e3a \"gpt-4o-mini\"</li> <li><code>summarizer_max_tokens</code>: \u6458\u8981\u6a21\u578b\u7684\u6700\u5927 token \u6570\uff0c\u9ed8\u8ba4\u4e3a 400</li> <li><code>summarizer_tools_json</code>: \u6458\u8981\u5668\u7684\u5de5\u5177\u914d\u7f6e\uff08JSON \u5b57\u7b26\u4e32\uff09\uff0c\u9ed8\u8ba4\u4e3a \"[]\"</li> <li><code>summarizer_tool_choice</code>: \u6458\u8981\u5668\u7684\u5de5\u5177\u9009\u62e9\u7b56\u7565\uff0c\u9ed8\u8ba4\u4e3a \"none\"</li> </ul>"},{"location":"1-4%20Basic%20Concepts%20CE%20Node/#ce-node-input-and-output","title":"CE Node Input and Output","text":"<p>\u9ed8\u8ba4\u7684\u6570\u636e\u7c7b\u578b\u4e3a <code>std::string</code>\uff08\u81ea\u5b9a\u4e49\u6570\u636e\u7c7b\u578b\u8bf7\u53c2\u8003 <code>Advanced Usage</code>\uff09\u3002</p>"},{"location":"1-4%20Basic%20Concepts%20CE%20Node/#input-format","title":"Input Format","text":"<p>\u8f93\u5165\u6570\u636e\u683c\u5f0f\u4e25\u683c\u9075\u5faa OpenAI Chat Completion API \u89c4\u8303\uff0c\u683c\u5f0f\u5982\u4e0b\uff1a</p> <pre><code>[\n  {\"role\":\"system\",\"content\":\"you are a helpful assistant\"},\n  {\"role\":\"user\",\"content\":\"who are you?\"},\n  {\"role\":\"assistant\",\"content\":\"my name is bob.\"},\n  {\"role\":\"user\",\"content\":\"what can you do?\"}\n]\n</code></pre>"},{"location":"1-4%20Basic%20Concepts%20CE%20Node/#output-format","title":"Output Format","text":"<p>\u8f93\u51fa\u6570\u636e\u683c\u5f0f\u540c\u6837\u9075\u5faa OpenAI Chat Completion API \u89c4\u8303\u3002\u6839\u636e\u914d\u7f6e\u7684\u7b56\u7565\uff0c\u8f93\u51fa\u53ef\u80fd\u662f\uff1a</p> <ul> <li>TRIMMING \u7b56\u7565\uff1a\u4fdd\u7559\u6700\u8fd1 <code>max_turns</code> \u8f6e\u5bf9\u8bdd\u7684\u539f\u59cb\u6d88\u606f</li> <li>SUMMARIZING \u7b56\u7565\uff1a\u5c06\u8d85\u51fa <code>keep_last_n_turns</code> \u7684\u65e7\u6d88\u606f\u538b\u7f29\u4e3a\u6458\u8981\uff0c\u4fdd\u7559\u6700\u8fd1 <code>keep_last_n_turns</code> \u8f6e\u7684\u539f\u59cb\u6d88\u606f</li> </ul> <p>\u8f93\u51fa\u683c\u5f0f\u793a\u4f8b\uff1a</p> <pre><code>[\n  {\"role\":\"system\",\"content\":\"you are a helpful assistant\"},\n  {\"role\":\"assistant\",\"content\":\"[Summary of previous conversation]\"},\n  {\"role\":\"user\",\"content\":\"what can you do?\"}\n]\n</code></pre>"},{"location":"1-5%20Basic%20Concepts%20Chain%20Flow/","title":"Chain","text":"<p>The <code>chain</code> function is used to connect two nodes, creating a data flow path between nodes. An optional <code>action</code> parameter can be specified to create conditional connections.</p> <p>Function Signature:</p> <pre><code>template &lt;typename NodeA, typename NodeB&gt;\nvoid chain(\n    const std::shared_ptr&lt;NodeA&gt;&amp; a,      // Source node\n    const std::shared_ptr&lt;NodeB&gt;&amp; b,      // Target node\n    std::optional&lt;std::string&gt; action = std::nullopt  // Optional action identifier\n);\n</code></pre> <p>How It Works:</p> <ul> <li>When the <code>action</code> parameter is <code>std::nullopt</code>, it creates a default connection (unconditional connection)</li> <li>When the <code>action</code> parameter has a value, it creates a conditional connection, which only executes when the action value returned by the source node's <code>route</code> function matches the action specified in <code>chain</code></li> </ul> <p>Usage Example:</p> <pre><code>// Set routing: determine the returned action based on node output\nroute(decide_node, [](const std::string&amp;, const std::string&amp;) -&gt; std::optional&lt;std::string&gt; {\n    // Return different actions based on business logic\n    return \"search\";\n});\n\n// Create conditional connection: execute this connection when route returns \"search\"\nchain(decide_node, search_node, \"search\");\n\n// Create conditional connection: execute this connection when route returns \"answer\"\nchain(decide_node, answer_node, \"answer\");\n\n// Create default connection: execute unconditionally (used when route returns std::nullopt)\nchain(decide_node, default_node);\n</code></pre> <p>Notes: - The route function is called after the node execution completes - The returned action value must match the action specified in <code>chain</code> - When returning <code>std::nullopt</code>, use the default connection (chain without action parameter)</p>"},{"location":"1-5%20Basic%20Concepts%20Chain%20Flow/#flow","title":"Flow","text":"<p>Flow is the execution container for workflows, used in conjunction with Chain. It is responsible for managing node execution order and data flow. Through Flow, multiple nodes can be organized into a complete execution flow.</p>"},{"location":"1-5%20Basic%20Concepts%20Chain%20Flow/#basic-concepts-of-flow","title":"Basic Concepts of Flow","text":"<ul> <li>Workflow Container: Flow is the execution container for nodes, managing node lifecycle and execution order</li> <li>Start Node: Each Flow must specify a start node as the workflow entry point</li> <li>Automatic Execution: Flow automatically executes the workflow based on connections between nodes</li> <li>Type Safety: Flow supports typed input and output, ensuring type safety</li> </ul>"},{"location":"1-5%20Basic%20Concepts%20Chain%20Flow/#creating-and-executing-workflows","title":"Creating and Executing Workflows","text":""},{"location":"1-5%20Basic%20Concepts%20Chain%20Flow/#1-create-flow-object","title":"1. Create Flow Object","text":"<p>Use <code>std::make_shared</code> to create a Flow object:</p> <pre><code>auto f = std::make_shared&lt;nodeflow::Flow&gt;();\n</code></pre>"},{"location":"1-5%20Basic%20Concepts%20Chain%20Flow/#2-set-start-node","title":"2. Set Start Node","text":"<p>Specify the workflow's start node through the <code>start</code> method:</p> <pre><code>f-&gt;start(decide_node);  // decide_node as the workflow entry point\n</code></pre>"},{"location":"1-5%20Basic%20Concepts%20Chain%20Flow/#3-execute-workflow","title":"3. Execute Workflow","text":"<p>Use the <code>runWithInput</code> method to execute the workflow:</p> <pre><code>auto result = f-&gt;runWithInput&lt;std::string, std::string&gt;(input);\n</code></pre> <p>Function Signature:</p> <pre><code>template &lt;typename IN, typename OUT&gt;\nOUT runWithInput(const IN&amp; input);\n</code></pre> <p>Parameter Description: - Template parameter <code>IN</code>: Input data type (i.e., the first node's input) - Template parameter <code>OUT</code>: Output data type - <code>input</code>: Actual input data</p> <p>Return Value: - The workflow's final output result, type is <code>OUT</code></p>"},{"location":"2-1%20Application%20Development%20Single%20Node%20Agent/","title":"Single Node Agent Development Example","text":""},{"location":"2-1%20Application%20Development%20Single%20Node%20Agent/#overview","title":"Overview","text":"<p>Chat Node is a node component that integrates large language models (LLM) and function calling capabilities, supporting both online and offline model invocation. Its interface strictly follows the OpenAI Chat Completion API specification.</p>"},{"location":"2-1%20Application%20Development%20Single%20Node%20Agent/#development-steps","title":"Development Steps","text":""},{"location":"2-1%20Application%20Development%20Single%20Node%20Agent/#1-register-tools","title":"1. Register Tools","text":"<p>Before using Chat Node, you need to register the required tools first. Tools are divided into two categories:</p> <ul> <li>Local Tools: Need to implement tool classes in advance. For development specifications, please refer to <code>Local Tool Development Specifications</code></li> <li>Remote Tools: Configured through server URLs</li> </ul>"},{"location":"2-1%20Application%20Development%20Single%20Node%20Agent/#11-register-local-tools","title":"1.1 Register Local Tools","text":"<p>Use the <code>add_function_call</code> method to register local tools. Tool descriptions must follow the OpenAI Function Call format:</p> <pre><code>#include &lt;tools.h&gt;\n#include &lt;web_search.h&gt;\n\ncommon_tools::tools::add_function_call(search_news_tool,\n    R\"({\"type\":\"function\",\"function\":{\"name\":\"search_news\",\"description\":\"Search the web using keywords to get the latest, time-sensitive information such as weather and news, supporting filtering by time range, country, etc. to get web content, titles, and link information\",\"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search query string used to search for relevant information on the web. Keyword combinations should be concise and clear, avoiding redundant information while ensuring they accurately reflect the core needs of the user's question. Keyword combinations should conform to search engine syntax and logical rules\",\"minLength\":1},\"time_range\":{\"type\":\"string\",\"description\":\"Time range used to limit search results from a specific time\",\"enum\":[\"day\",\"week\"]},\"country\":{\"type\":\"string\",\"description\":\"Region name (must be in English) used to limit search results from a specific region\",\"enum\":[\"china\",\"usa\",\"japan\",\"...\"]}},\"required\":[\"query\"]}}})\"\n);\n</code></pre> <p>Tool description JSON format example:</p> <pre><code>[\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"search_news\",\n      \"description\": \"Search for the latest news information\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"query\": {\n            \"type\": \"string\",\n            \"description\": \"Search keywords\"\n          }\n        },\n        \"required\": [\"query\"]\n      }\n    }\n  }\n]\n</code></pre>"},{"location":"2-1%20Application%20Development%20Single%20Node%20Agent/#12-register-remote-tool-server","title":"1.2 Register Remote Tool Server","text":"<p>Use the <code>add_server</code> method to register a remote tool server:</p> <pre><code>#include &lt;tools.h&gt;\n\ncommon_tools::tools::add_server(\n    R\"({\"WeatherServer\":{\"url\":\"http://18.119.131.41:8006\",\"sse_endpoint\":\"/sse\"}})\"\n);\n</code></pre>"},{"location":"2-1%20Application%20Development%20Single%20Node%20Agent/#2-configure-chat-node","title":"2. Configure Chat Node","text":"<p>Create a <code>chat_node_settings</code> object and configure model parameters:</p> <pre><code>#include &lt;tools.h&gt;\n\nchat_node::chat_node_settings s_generate;\ns_generate.model = \"gpt-4.1\";           // Model name\ns_generate.temperature = 0.7;           // Temperature parameter, controls output randomness\ns_generate.top_p = 0.95;                 // Top-p sampling parameter\ns_generate.max_tokens = 4096;           // Maximum generated tokens\ns_generate.tool_choice = \"auto\";        // Tool selection strategy: auto/none/required\ns_generate.tools_json = common_tools::tools::get_all_tools_json();  // Get all registered tools\n</code></pre>"},{"location":"2-1%20Application%20Development%20Single%20Node%20Agent/#3-create-workflow","title":"3. Create Workflow","text":""},{"location":"2-1%20Application%20Development%20Single%20Node%20Agent/#31-create-chat-node-instance","title":"3.1 Create Chat Node Instance","text":"<pre><code>const auto generate_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_generate);\n</code></pre>"},{"location":"2-1%20Application%20Development%20Single%20Node%20Agent/#32-create-and-configure-flow","title":"3.2 Create and Configure Flow","text":"<pre><code>auto f = std::make_shared&lt;nodeflow::Flow&gt;();\nf-&gt;start(generate_node);  // Set the workflow's start node\n</code></pre>"},{"location":"2-1%20Application%20Development%20Single%20Node%20Agent/#33-execute-workflow","title":"3.3 Execute Workflow","text":"<p>Use the <code>runWithInput</code> method to execute the workflow:</p> <pre><code>auto result = f-&gt;runWithInput&lt;std::string, std::string&gt;(message);\n</code></pre> <p>Parameter Description: - Template parameter <code>IN</code>: Input data type - Template parameter <code>OUT</code>: Output data type - <code>input</code>: Actual input data</p> <p>Return Value: - The workflow's final output result, type is <code>OUT</code></p>"},{"location":"2-1%20Application%20Development%20Single%20Node%20Agent/#complete-example","title":"Complete Example","text":"<p>The following is a complete single node agent implementation example:</p> <pre><code>#include &lt;chat_node.h&gt;\n#include &lt;log_util.hpp&gt;\n#include &lt;nodeflow.hpp&gt;\n#include &lt;tools.h&gt;\n#include &lt;web_search.h&gt;\n#include &lt;nlohmann/json.hpp&gt;\n\n// Register local tools\ncommon_tools::tools::add_function_call(search_news_tool,\n    R\"({\"type\":\"function\",\"function\":{\"name\":\"search_news\",\"description\":\"Search the web using keywords to get the latest, time-sensitive information such as weather and news, supporting filtering by time range, country, etc. to get web content, titles, and link information\",\"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search query string used to search for relevant information on the web. Keyword combinations should be concise and clear, avoiding redundant information while ensuring they accurately reflect the core needs of the user's question. Keyword combinations should conform to search engine syntax and logical rules\",\"minLength\":1},\"time_range\":{\"type\":\"string\",\"description\":\"Time range used to limit search results from a specific time\",\"enum\":[\"day\",\"week\"]},\"country\":{\"type\":\"string\",\"description\":\"Region name (must be in English) used to limit search results from a specific region\",\"enum\":[\"china\",\"usa\",\"japan\",\"...\"]}},\"required\":[\"query\"]}}})\"\n);\n\n// Register remote tool server\ncommon_tools::tools::add_server(\n    R\"({\"WeatherServer\":{\"url\":\"http://18.119.131.41:8006\",\"sse_endpoint\":\"/sse\"}})\"\n);\n\nstd::string call_tool_impl_cpp(const std::string&amp; message)\n{\n    try\n    {\n        HYB_LOG_INFO(\"===== call_tool_impl_cpp BEGIN =====\");\n\n        // Configure Chat Node parameters\n        chat_node::chat_node_settings s_generate;\n        s_generate.model = \"gpt-4.1\";\n        s_generate.temperature = 0.7;\n        s_generate.top_p = 0.95;\n        s_generate.max_tokens = 4096;\n        s_generate.tool_choice = \"auto\";\n        s_generate.tools_json = common_tools::tools::get_all_tools_json();\n\n        // Create Chat Node instance\n        const auto generate_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_generate);\n\n        // Create workflow and set start node\n        auto f = std::make_shared&lt;nodeflow::Flow&gt;();\n        f-&gt;start(generate_node);\n\n        // Execute workflow\n        auto result = f-&gt;runWithInput&lt;std::string, std::string&gt;(message);\n\n        return result;\n    }\n    catch (const std::exception&amp; ex)\n    {\n        HYB_LOG_ERROR(std::string(\"call_tool_impl_cpp exception: \") + ex.what());\n        return R\"({\"ok\":false,\"error\":\"exception\"})\";\n    }\n    catch (...)\n    {\n        HYB_LOG_ERROR(\"call_tool_impl_cpp unknown exception\");\n        return R\"({\"ok\":false,\"error\":\"unknown exception\"})\";\n    }\n}\n\nint main()\n{\n    // Build input message (OpenAI Chat Completion format)\n    nlohmann::json inputJson = nlohmann::json::array();\n    inputJson.push_back({\n        {\"role\", \"system\"},\n        {\"content\", \"you are a helper\"}\n    });\n    inputJson.push_back({\n        {\"role\", \"user\"},\n        {\"content\", \"hello there\"}\n    });\n\n    // Call agent and get response\n    const char* response = call_tool_impl_cpp(inputJson.dump().c_str());\n    std::string responseStr(response);\n\n    // Response contains complete conversation history\n    std::cout &lt;&lt; responseStr &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"2-2%20Application%20Development%20Two%20Node%20Agent/","title":"Two Node Agent Development Example","text":""},{"location":"2-2%20Application%20Development%20Two%20Node%20Agent/#overview","title":"Overview","text":"<p>A two node agent builds upon a single node agent by connecting nodes in series to achieve more complex workflows. This example demonstrates how to connect two Chat Node nodes in series: the first node (<code>generate_node</code>) is responsible for generating content and invoking tools, while the second node (<code>polish_node</code>) is responsible for polishing and stylizing the output of the first node.</p> <p>Workflow Diagram:</p> <pre><code>Input \u2192 generate_node (Generate + Tool Call) \u2192 polish_node (Polish) \u2192 Output\n</code></pre>"},{"location":"2-2%20Application%20Development%20Two%20Node%20Agent/#development-steps","title":"Development Steps","text":""},{"location":"2-2%20Application%20Development%20Two%20Node%20Agent/#1-register-tools","title":"1. Register Tools","text":"<p>Same as a single node agent, you need to register the required tools first. For detailed steps, please refer to the single node agent development documentation.</p>"},{"location":"2-2%20Application%20Development%20Two%20Node%20Agent/#2-configure-the-first-node-generate-node","title":"2. Configure the First Node (Generate Node)","text":"<p>Create and configure the first Chat Node for generating content and invoking tools:</p> <pre><code>#include &lt;tools.h&gt;\n\nchat_node::chat_node_settings s_generate;\ns_generate.model = \"gpt-4.1\";           // Use a more powerful model\ns_generate.temperature = 0.7;\ns_generate.top_p = 0.95;\ns_generate.max_tokens = 4096;\ns_generate.tool_choice = \"auto\";        // Allow automatic tool invocation\ns_generate.tools_json = common_tools::tools::get_all_tools_json();\nconst auto generate_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_generate);\n</code></pre>"},{"location":"2-2%20Application%20Development%20Two%20Node%20Agent/#3-configure-the-second-node-polish-node","title":"3. Configure the Second Node (Polish Node)","text":"<p>Create and configure the second Chat Node for polishing the output of the first node:</p> <pre><code>chat_node::chat_node_settings s_polish;\ns_polish.model = \"gpt-4o-mini\";         // Use a more economical model for polishing\ns_polish.temperature = 0.7;\ns_polish.top_p = 0.95;\ns_polish.max_tokens = 4096;\ns_polish.tool_choice = \"none\";          // Polish node doesn't need to invoke tools\nconst auto polish_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_polish);\n</code></pre>"},{"location":"2-2%20Application%20Development%20Two%20Node%20Agent/#4-configure-node-preprocessing-and-postprocessing-advanced-application","title":"4. Configure Node Preprocessing and Postprocessing (<code>Advanced Application</code>)","text":"<p>HADK supports setting preprocessor and postprocessor functions for each node, used for customizing data processing before and after node execution.</p>"},{"location":"2-2%20Application%20Development%20Two%20Node%20Agent/#41-set-preprocessor-function","title":"4.1 Set Preprocessor Function","text":"<p>The preprocessor function modifies input data before node execution, commonly used for Prompt Engineering (PE) optimization:</p> <pre><code>polish_node-&gt;setPreprocessor([](const std::string&amp; in) -&gt; std::string {\n    HYB_LOG_INFO(\"polish_node input: {}\", in);\n\n    // Parse input JSON\n    nlohmann::json inJson = nlohmann::json::parse(in);\n\n    // Extract the content of the last message\n    std::string content = inJson.back()[\"content\"].get&lt;std::string&gt;();\n\n    // Build polishing prompt\n    std::string prompt = R\"(\n### CONTEXT\npolish the following content:\nContent: )\" + content + R\"(\n## YOUR ANSWER:\nProvide a comprehensive answer using the content.)\";\n\n    // Update message content\n    inJson.back()[\"content\"] = prompt;\n    return inJson.dump();\n});\n</code></pre>"},{"location":"2-2%20Application%20Development%20Two%20Node%20Agent/#42-set-postprocessor-function","title":"4.2 Set Postprocessor Function","text":"<p>The postprocessor function modifies output data after node execution, commonly used for result parsing and formatting:</p> <pre><code>polish_node-&gt;setPostprocessor([](const std::string&amp; output) -&gt; std::string {\n    HYB_LOG_INFO(\"polish_node output: {}\", output);\n    // You can parse, format, etc. the output here\n    return output;\n});\n</code></pre>"},{"location":"2-2%20Application%20Development%20Two%20Node%20Agent/#5-connect-nodes-in-series","title":"5. Connect Nodes in Series","text":"<p>Use the <code>chain</code> function to connect the two nodes in series, establishing data flow:</p> <pre><code>chain(generate_node, polish_node, \"polish\");\n</code></pre> <p>Parameter Description: - First parameter: Source node (<code>generate_node</code>) - Second parameter: Target node (<code>polish_node</code>) - Third parameter: Connection name (optional, used to identify the connection)</p> <p>Execution Flow: 1. <code>generate_node</code> receives input and generates content (may invoke tools) 2. <code>generate_node</code>'s output is automatically passed to <code>polish_node</code> 3. <code>polish_node</code> polishes the input 4. <code>polish_node</code>'s output is returned as the final result</p>"},{"location":"2-2%20Application%20Development%20Two%20Node%20Agent/#6-create-workflow-and-execute","title":"6. Create Workflow and Execute","text":"<pre><code>// Create workflow\nauto f = std::make_shared&lt;nodeflow::Flow&gt;();\n\n// Set start node (must be the first node in the workflow)\nf-&gt;start(generate_node);\n\n// Execute workflow\nauto result = f-&gt;runWithInput&lt;std::string, std::string&gt;(message);\n</code></pre> <p>Parameter Description: - Template parameter <code>IN</code>: Input data type - Template parameter <code>OUT</code>: Output data type - <code>message</code>: Actual input data (JSON string in OpenAI Chat Completion format)</p> <p>Return Value: - The workflow's final output result, type is <code>OUT</code></p>"},{"location":"2-2%20Application%20Development%20Two%20Node%20Agent/#complete-example","title":"Complete Example","text":"<p>The following is a complete two node agent implementation example:</p> <pre><code>#include &lt;chat_node.h&gt;\n#include &lt;log_util.hpp&gt;\n#include &lt;nodeflow.hpp&gt;\n#include &lt;tools.h&gt;\n#include &lt;web_search.h&gt;\n#include &lt;nlohmann/json.hpp&gt;\n\n// Register local tools\ncommon_tools::tools::add_function_call(search_news_tool,\n    R\"({\"type\":\"function\",\"function\":{\"name\":\"search_news\",\"description\":\"Search the web using keywords to get the latest, time-sensitive information such as weather and news, supporting filtering by time range, country, etc. to get web content, titles, and link information\",\"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search query string used to search for relevant information on the web. Keyword combinations should be concise and clear, avoiding redundant information while ensuring they accurately reflect the core needs of the user's question. Keyword combinations should conform to search engine syntax and logical rules\",\"minLength\":1},\"time_range\":{\"type\":\"string\",\"description\":\"Time range used to limit search results from a specific time\",\"enum\":[\"day\",\"week\"]},\"country\":{\"type\":\"string\",\"description\":\"Region name (must be in English) used to limit search results from a specific region\",\"enum\":[\"china\",\"usa\",\"japan\",\"...\"]}},\"required\":[\"query\"]}}})\"\n);\n\n// Register remote tool server\ncommon_tools::tools::add_server(\n    R\"({\"WeatherServer\":{\"url\":\"http://18.119.131.41:8006\",\"sse_endpoint\":\"/sse\"}})\"\n);\n\nstd::string call_tool_impl_cpp(const std::string&amp; message)\n{\n    try\n    {\n        HYB_LOG_INFO(\"===== call_tool_impl_cpp BEGIN =====\");\n\n        // Create workflow\n        auto f = std::make_shared&lt;nodeflow::Flow&gt;();\n\n        // Configure first node: Generate node (supports tool invocation)\n        chat_node::chat_node_settings s_generate;\n        s_generate.model = \"gpt-4.1\";\n        s_generate.temperature = 0.7;\n        s_generate.top_p = 0.95;\n        s_generate.max_tokens = 4096;\n        s_generate.tool_choice = \"auto\";\n        s_generate.tools_json = common_tools::tools::get_all_tools_json();\n        const auto generate_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_generate);\n\n        // Configure second node: Polish node (doesn't invoke tools)\n        chat_node::chat_node_settings s_polish;\n        s_polish.model = \"gpt-4o-mini\";\n        s_polish.temperature = 0.7;\n        s_polish.top_p = 0.95;\n        s_polish.max_tokens = 4096;\n        s_polish.tool_choice = \"none\";\n        const auto polish_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_polish);\n\n        // Set polish node's preprocessor function\n        polish_node-&gt;setPreprocessor([](const std::string&amp; in) -&gt; std::string {\n            HYB_LOG_INFO(\"polish_node input: {}\", in);\n\n            // Parse input JSON\n            nlohmann::json inJson = nlohmann::json::parse(in);\n\n            // Extract the content of the last message\n            std::string content = inJson.back()[\"content\"].get&lt;std::string&gt;();\n\n            // Build polishing prompt\n            std::string prompt = R\"(\n### CONTEXT\npolish the following content:\nContent: )\" + content + R\"(\n## YOUR ANSWER:\nProvide a comprehensive answer using the content.)\";\n\n            // Update message content\n            inJson.back()[\"content\"] = prompt;\n            return inJson.dump();\n        });\n\n        // Set polish node's postprocessor function\n        polish_node-&gt;setPostprocessor([](const std::string&amp; output) -&gt; std::string {\n            HYB_LOG_INFO(\"polish_node output: {}\", output);\n            // You can parse, format, etc. the output here\n            return output;\n        });\n\n        // Connect nodes in series: generate_node -&gt; polish_node\n        nodeflow::chain(generate_node, polish_node, \"polish\");\n\n        // Set workflow's start node\n        f-&gt;start(generate_node);\n\n        // Execute workflow\n        auto result = f-&gt;runWithInput&lt;std::string, std::string&gt;(message);\n\n        return result;\n    }\n    catch (const std::exception&amp; ex)\n    {\n        HYB_LOG_ERROR(std::string(\"call_tool_impl_cpp exception: \") + ex.what());\n        return R\"({\"ok\":false,\"error\":\"exception\"})\";\n    }\n    catch (...)\n    {\n        HYB_LOG_ERROR(\"call_tool_impl_cpp unknown exception\");\n        return R\"({\"ok\":false,\"error\":\"unknown exception\"})\";\n    }\n}\n\nint main()\n{\n    // Build input message (OpenAI Chat Completion format)\n    nlohmann::json inputJson = nlohmann::json::array();\n    inputJson.push_back({\n        {\"role\", \"system\"},\n        {\"content\", \"you are a helper\"}\n    });\n    inputJson.push_back({\n        {\"role\", \"user\"},\n        {\"content\", \"hello there\"}\n    });\n\n    // Call agent and get response\n    std::string response = call_tool_impl_cpp(inputJson.dump());\n\n    // Response contains complete conversation history\n    std::cout &lt;&lt; response &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/","title":"Conditional Routing Agent Development Example","text":""},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#overview","title":"Overview","text":"<p>The conditional routing agent demonstrates how to use HADK's conditional routing (<code>route</code>) functionality to implement complex workflows. This example implements a research assistant agent that can dynamically decide whether to continue searching for information or directly answer questions based on the current context, supporting iterative searches until sufficient information is obtained.</p> <p>Workflow Diagram:</p> <pre><code>Input \u2192 decide_node (Decision) \u2192 [Conditional Routing]\n                                  \u251c\u2500 \"search\" \u2192 web_search_node (Web Search) \u2192 decide_node (Loop)\n                                  \u2514\u2500 \"answer\" \u2192 answer_node (Generate Answer) \u2192 Output\n</code></pre> <p>Core Features: - Conditional routing: Dynamically select the next node based on the decision node's output - Loop workflow: Supports looping between decision node and search node until sufficient information is obtained - Context accumulation: Each search result accumulates into the context for subsequent decisions</p>"},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#development-steps","title":"Development Steps","text":""},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#1-register-tools","title":"1. Register Tools","text":"<p>Same as a single node agent, you need to register the required tools first. This example uses the <code>search_web2</code> tool for web search:</p> <pre><code>#include &lt;tools.h&gt;\n#include &lt;web_search.h&gt;\n\ncommon_tools::tools::add_function_call(search_web_tool,\n    R\"({\"type\":\"function\",\"function\":{\"name\":\"search_web2\",\"description\":\"Search the web using keywords to get general information that doesn't change over time, supporting filtering by country, etc. to get web content, titles, and link information\",\"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search query string used to search for relevant information on the web. Keyword combinations should be concise and clear, avoiding redundant information while ensuring they accurately reflect the core needs of the user's question. Keyword combinations should conform to search engine syntax and logical rules\",\"minLength\":1},\"country\":{\"type\":\"string\",\"description\":\"Country name (must be in English) used to limit search results from a specific country\",\"enum\":[\"china\",\"usa\",\"japan\",\"...\"]}},\"required\":[\"query\"]}}})\"\n);\n</code></pre>"},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#2-configure-decision-node-decide-node","title":"2. Configure Decision Node (Decide Node)","text":"<p>The decision node is responsible for analyzing the current context and deciding the next action (search or answer):</p> <pre><code>chat_node::chat_node_settings s1;\ns1.model = \"gpt-4o-mini\";\ns1.temperature = 0.7;\ns1.top_p = 0.95;\ns1.max_tokens = 2048;\ns1.tool_choice = \"none\"; \nconst auto decide_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s1);\n</code></pre>"},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#3-configure-decision-node-preprocessing-and-postprocessing","title":"3. Configure Decision Node Preprocessing and Postprocessing","text":""},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#31-set-preprocessor-function","title":"3.1 Set Preprocessor Function","text":"<p>The preprocessor function builds a decision prompt containing the question, existing context, and available actions:</p> <pre><code>decide_node-&gt;setPreprocessor([&amp;](const std::string&amp; in) -&gt; std::string {\n    nlohmann::json inJson = nlohmann::json::parse(in);\n\n    g_question = inJson[0][\"content\"].get&lt;std::string&gt;();\n\n    std::string prompt = build_ws_prompt(g_question, g_context);\n    inJson[0][\"content\"] = prompt;\n    return inJson.dump();\n});\n</code></pre> <p><code>build_ws_prompt</code> function example:</p> <pre><code>static std::string build_ws_prompt(const std::string &amp;question, const std::string &amp;context) {\n    auto now = std::chrono::system_clock::now();\n    const std::string local_time = fmt::format(\"{:%Y-%m-%d %H:%M:%S}\", now);\n\n    return R\"(### CONTEXT\nYou are a research assistant that can search the web.\nQuestion: )\" + question + R\"(\nPrevious Research: )\" + context + R\"(\n\n### ACTION SPACE\n[1] search\nDescription: Look up more information on the web\nParameters:\n    - query (str): What to search for\n\n[2] answer\nDescription: Answer the question with current knowledge\nParameters:\n    - answer (str): Final answer to the question\n\n## NEXT ACTION\nDecide the next action based on the context and available actions.\nReturn your response in this format:\n\n```yaml\nthinking: |\n    &lt;your step-by-step reasoning process&gt;\naction: search OR answer\nreason: |\n    &lt;why you chose this action&gt;\nanswer: |\n    &lt;if action is answer&gt;\nsearch_query: &lt;specific search query if action is search&gt;\n</code></pre> <p>Current time: )\" + local_time; }</p> <pre><code>\n#### 3.2 Set Postprocessor Function\n\nThe postprocessor function parses the YAML-formatted decision result and extracts the action type and parameters:\n\n```c++\ndecide_node-&gt;setPostprocessor([&amp;](const std::string&amp; output) -&gt; std::string {\n    nlohmann::json output_Json = nlohmann::json::parse(output);\n\n    // Extract and clean response content (remove code block markers)\n    std::string cleaned_response = StripFenceRegex(\n        output_Json.back()[\"content\"].get&lt;std::string&gt;());\n\n    // Parse YAML\n    g_yaml_node = YAML::Load(cleaned_response);\n\n    // Check required fields\n    if (!g_yaml_node[\"thinking\"] || !g_yaml_node[\"action\"] || !g_yaml_node[\"reason\"]) {\n        HYB_LOG_WARN(\"Missing required YAML fields\");\n        return \"search\";  // Default to search on error\n    }\n\n    // Return different values based on action type\n    if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"search\") {\n        return g_yaml_node[\"search_query\"].as&lt;std::string&gt;();  // Return search query\n    }\n\n    if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"answer\") {\n        // Build final answer prompt\n        std::string prompt = R\"(### CONTEXT\nBased on the following information, answer the question.\nQuestion: )\" + g_question + R\"(\nResearch: )\" + g_context + R\"(\n\n## YOUR ANSWER:\nProvide a comprehensive answer using the research results.)\";\n        return prompt;\n    }\n\n    return \"search\";  // Default to search\n});\n</code></pre>"},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#4-configure-conditional-routing","title":"4. Configure Conditional Routing","text":"<p>Use the <code>route</code> function to configure conditional routing for the decision node, selecting the next node based on the postprocessor function's output:</p> <pre><code>route(decide_node, [&amp;](const std::string &amp;input, const std::string &amp;output) -&gt; std::optional&lt;std::string&gt; {\n    if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"search\") {\n        return \"search\";  // Route to search node\n    }\n\n    if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"answer\") {\n        return \"answer\";  // Route to answer node\n    }\n\n    return std::nullopt;  // No matching route\n});\n</code></pre> <p>Parameter Description: - First parameter: Source node (<code>decide_node</code>) - Second parameter: Route function that receives input and output, returns route name (<code>std::optional&lt;std::string&gt;</code>)</p>"},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#5-configure-search-node-web-search-node","title":"5. Configure Search Node (Web Search Node)","text":"<p>The search node uses <code>OneFuncNode</code> to implement custom logic, invoke tools, and process results:</p> <pre><code>auto web_search_node = std::make_shared&lt;nodeflow::OneFuncNode&lt;std::string, std::string&gt;&gt;(\n    [&amp;](const std::string &amp;input) -&gt; std::string {\n        // Build tool invocation parameters\n        nlohmann::json ws_in_json;\n        ws_in_json[\"query\"] = input;  // input is the search query string\n\n        // Invoke search tool\n        std::string ws_out = common_tools::tools::call_tool(\"search_web2\", ws_in_json.dump());\n\n        // Parse tool return result (tool returns wrapped JSON)\n        nlohmann::json ws_out_json = nlohmann::json::parse(ws_out);\n\n        std::string web_content;\n        try {\n            // Extract actual search results from wrapped JSON\n            if (ws_out_json.contains(\"content\") &amp;&amp; \n                ws_out_json[\"content\"].is_array() &amp;&amp; \n                !ws_out_json[\"content\"].empty()) {\n                const auto &amp;first = ws_out_json[\"content\"][0];\n                if (first.contains(\"type\") &amp;&amp; \n                    first[\"type\"].get&lt;std::string&gt;() == \"text\" &amp;&amp; \n                    first.contains(\"text\")) {\n                    // Parse actual search results again\n                    nlohmann::json ws_payload = nlohmann::json::parse(\n                        first[\"text\"].get&lt;std::string&gt;());\n\n                    // Extract and format search results\n                    if (ws_payload.contains(\"responses\") &amp;&amp; \n                        ws_payload[\"responses\"].is_array()) {\n                        for (const auto &amp;resp : ws_payload[\"responses\"]) {\n                            web_content +=\n                                \"TITLE: \" + resp[\"title\"].get&lt;std::string&gt;() +\n                                \"\\nURL: \" + resp[\"url\"].get&lt;std::string&gt;() +\n                                \"\\nSNIPPET: \" + resp[\"snippet\"].get&lt;std::string&gt;() +\n                                \"\\n\\n\";\n                        }\n                    }\n                }\n            }\n        } catch (const std::exception &amp;e) {\n            HYB_LOG_ERROR(\"Failed to parse search results: {}\", e.what());\n        }\n\n        // Accumulate context\n        std::string new_context = \n            g_context +\n            \"\\n\\nSEARCH: \" + input +\n            \"\\n\\nRESULTS: \\n\" + \n            (!web_content.empty() ? web_content : \"No results\");\n\n        g_context = new_context;\n\n        // Return question for re-entering decision node\n        nlohmann::json output_json = nlohmann::json::array();\n        output_json.push_back({{\"role\", \"user\"}, {\"content\", g_question}});\n        return output_json.dump();\n    });\n</code></pre>"},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#6-configure-search-node-routing","title":"6. Configure Search Node Routing","text":"<p>The search node always returns to the decision node after execution, forming a loop:</p> <pre><code>route(web_search_node, [&amp;](const std::string &amp;input, const std::string &amp;output) -&gt; std::optional&lt;std::string&gt; {\n    return \"decide\";  // Always route back to decision node\n});\n</code></pre>"},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#7-configure-answer-node-answer-node","title":"7. Configure Answer Node (Answer Node)","text":"<p>The answer node generates the final answer:</p> <pre><code>chat_node::chat_node_settings s_answer;\nconst auto answer_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_answer);\n\nanswer_node-&gt;setPreprocessor([&amp;](const std::string &amp;in) -&gt; std::string {\n    // Convert input to Chat Completion format\n    nlohmann::json inJson = nlohmann::json::array();\n    inJson.push_back({{\"role\", \"user\"}, {\"content\", in}});\n    return inJson.dump();\n});\n</code></pre>"},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#8-connect-nodes","title":"8. Connect Nodes","text":"<p>Use the <code>chain</code> function to establish connections between nodes:</p> <pre><code>// Decision node to search node\nnodeflow::chain(decide_node, web_search_node, \"search\");\n\n// Decision node to answer node\nnodeflow::chain(decide_node, answer_node, \"answer\");\n\n// Search node back to decision node (forms loop)\nnodeflow::chain(web_search_node, decide_node, \"decide\");\n</code></pre>"},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#9-create-workflow-and-execute","title":"9. Create Workflow and Execute","text":"<pre><code>// Create workflow\nauto f = std::make_shared&lt;nodeflow::Flow&gt;();\n\n// Set start node\nf-&gt;start(decide_node);\n\n// Execute workflow\nauto result = f-&gt;runWithInput&lt;std::string, std::string&gt;(question);\n</code></pre> <p>Execution Flow: 1. Input question enters <code>decide_node</code> 2. <code>decide_node</code> analyzes context and decides to search or answer 3. If search is chosen:    - Route to <code>web_search_node</code> to execute search    - Search results accumulate into context    - Route back to <code>decide_node</code> (loop) 4. If answer is chosen:    - Route to <code>answer_node</code> to generate final answer    - Return result</p>"},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#complete-example","title":"Complete Example","text":"<p>The following is a complete conditional routing agent implementation example:</p> <pre><code>#include &lt;chat_node.h&gt;\n#include &lt;log_util.hpp&gt;\n#include &lt;nodeflow.hpp&gt;\n#include &lt;tools.h&gt;\n#include &lt;web_search.h&gt;\n#include &lt;nlohmann/json.hpp&gt;\n#include &lt;yaml-cpp/yaml.h&gt;\n#include &lt;fmt/chrono.h&gt;\n#include &lt;chrono&gt;\n#include &lt;regex&gt;\n#include &lt;iostream&gt;\n\nstd::string StripFenceRegex(std::string s) {\n    s = std::regex_replace(s, std::regex(R\"(^\\s*```[^\\r\\n]*\\r?\\n)\"), \"\");\n    s = std::regex_replace(s, std::regex(R\"((?:\\r?\\n)?\\s*```\\s*$)\"), \"\");\n    return s;\n}\n\nstatic std::string build_ws_prompt(const std::string &amp;question, const std::string &amp;context) {\n    auto now = std::chrono::system_clock::now();\n    const std::string local_time = fmt::format(\"{:%Y-%m-%d %H:%M:%S}\", now);\n\n    return R\"(### CONTEXT\n            You are a research assistant that can search the web.\n            Question: )\" + question + R\"(\n            Previous Research: )\" + context + R\"(\n\n            ### ACTION SPACE\n            [1] search\n            Description: Look up more information on the web\n            Parameters:\n                - query (str): What to search for\n\n            [2] answer\n            Description: Answer the question with current knowledge\n            Parameters:\n                - answer (str): Final answer to the question\n\n            ## NEXT ACTION\n            Decide the next action based on the context and available actions.\n            Return your response in this format:\n\n            ```yaml\n            thinking: |\n                &lt;your step-by-step reasoning process&gt;\n            action: search OR answer\n            reason: |\n                &lt;why you chose this action&gt;\n            answer: |\n                &lt;if action is answer&gt;\n            search_query: &lt;specific search query if action is search&gt;\n            ```\nCurrent time: )\" + local_time;\n}\n\n// Register tools\ncommon_tools::tools::add_function_call(search_web_tool,\n    R\"({\"type\":\"function\",\"function\":{\"name\":\"search_web2\",\"description\":\"Search the web using keywords to get general information that doesn't change over time, supporting filtering by country, etc. to get web content, titles, and link information\",\"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search query string used to search for relevant information on the web. Keyword combinations should be concise and clear, avoiding redundant information while ensuring they accurately reflect the core needs of the user's question. Keyword combinations should conform to search engine syntax and logical rules\",\"minLength\":1},\"country\":{\"type\":\"string\",\"description\":\"Country name (must be in English) used to limit search results from a specific country\",\"enum\":[\"china\",\"usa\",\"japan\",\"...\"]}},\"required\":[\"query\"]}}})\"\n);\n\nstd::string call_tool_impl_cpp(const std::string &amp;question) {\n    try {\n        // State variables\n        std::string g_context = \"\";\n        std::string g_question = \"\";\n        YAML::Node g_yaml_node = YAML::Node();\n\n        // Configure decision node\n        chat_node::chat_node_settings s1;\n        s1.model = \"gpt-4o-mini\";\n        s1.temperature = 0.7;\n        s1.top_p = 0.95;\n        s1.max_tokens = 2048;\n        s1.tool_choice = \"none\";\n        const auto decide_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s1);\n\n        // Set decision node's preprocessor function\n        decide_node-&gt;setPreprocessor([&amp;](const std::string&amp; in) -&gt; std::string {\n            nlohmann::json inJson = nlohmann::json::parse(in);\n            g_question = inJson[0][\"content\"].get&lt;std::string&gt;();\n            std::string prompt = build_ws_prompt(g_question, g_context);\n            inJson[0][\"content\"] = prompt;\n            return inJson.dump();\n        });\n\n        decide_node-&gt;setPostprocessor([&amp;](const std::string&amp; output) -&gt; std::string {\n            nlohmann::json output_Json = nlohmann::json::parse(output);\n            std::string cleaned_response = StripFenceRegex(\n                output_Json.back()[\"content\"].get&lt;std::string&gt;());\n\n            g_yaml_node = YAML::Load(cleaned_response);\n\n            if (!g_yaml_node[\"thinking\"] || !g_yaml_node[\"action\"] || !g_yaml_node[\"reason\"]) {\n                HYB_LOG_WARN(\"Missing required YAML fields\");\n                return \"search\";\n            }\n\n            HYB_LOG_INFO(\"Thinking: {}\", g_yaml_node[\"thinking\"].as&lt;std::string&gt;());\n            HYB_LOG_INFO(\"Action: {}\", g_yaml_node[\"action\"].as&lt;std::string&gt;());\n            HYB_LOG_INFO(\"Reason: {}\", g_yaml_node[\"reason\"].as&lt;std::string&gt;());\n\n            if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"search\") {\n                return g_yaml_node[\"search_query\"].as&lt;std::string&gt;();\n            }\n\n            if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"answer\") {\n                std::string prompt = R\"(### CONTEXT\nBased on the following information, answer the question.\nQuestion: )\" + g_question + R\"(\nResearch: )\" + g_context + R\"(\n\n## YOUR ANSWER:\nProvide a comprehensive answer using the research results.)\";\n                return prompt;\n            }\n\n            return \"search\";\n        });\n\n        // Configure decision node's conditional routing\n        route(decide_node, [&amp;](const std::string &amp;input, const std::string &amp;output) -&gt; std::optional&lt;std::string&gt; {\n            if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"search\") {\n                HYB_LOG_INFO(\"Routing to search node\");\n                return \"search\";\n            }\n            if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"answer\") {\n                HYB_LOG_INFO(\"Routing to answer node\");\n                return \"answer\";\n            }\n            return std::nullopt;\n        });\n\n        // Configure search node\n        auto web_search_node = std::make_shared&lt;nodeflow::OneFuncNode&lt;std::string, std::string&gt;&gt;(\n            [&amp;](const std::string &amp;input) -&gt; std::string {\n                // Build tool invocation parameters\n                nlohmann::json ws_in_json;\n                ws_in_json[\"query\"] = input;\n\n                // Invoke search tool\n                std::string ws_out = common_tools::tools::call_tool(\"search_web2\", ws_in_json.dump());\n                nlohmann::json ws_out_json = nlohmann::json::parse(ws_out);\n\n                // Parse search results\n                std::string web_content;\n                try {\n                    if (ws_out_json.contains(\"content\") &amp;&amp; \n                        ws_out_json[\"content\"].is_array() &amp;&amp; \n                        !ws_out_json[\"content\"].empty()) {\n                        const auto &amp;first = ws_out_json[\"content\"][0];\n                        if (first.contains(\"type\") &amp;&amp; \n                            first[\"type\"].get&lt;std::string&gt;() == \"text\" &amp;&amp; \n                            first.contains(\"text\")) {\n                            // Parse actual search results again\n                            nlohmann::json ws_payload = nlohmann::json::parse(\n                                first[\"text\"].get&lt;std::string&gt;());\n                            if (ws_payload.contains(\"responses\") &amp;&amp; \n                                ws_payload[\"responses\"].is_array()) {\n                                for (const auto &amp;resp : ws_payload[\"responses\"]) {\n                                    web_content +=\n                                        \"TITLE: \" + resp[\"title\"].get&lt;std::string&gt;() +\n                                        \"\\nURL: \" + resp[\"url\"].get&lt;std::string&gt;() +\n                                        \"\\nSNIPPET: \" + resp[\"snippet\"].get&lt;std::string&gt;() +\n                                        \"\\n\\n\";\n                                }\n                            }\n                        }\n                    }\n                } catch (const std::exception &amp;e) {\n                    HYB_LOG_ERROR(\"Failed to parse search results: {}\", e.what());\n                }\n\n                // Accumulate context\n                std::string new_context = \n                    g_context +\n                    \"\\n\\nSEARCH: \" + input +\n                    \"\\n\\nRESULTS: \\n\" + \n                    (!web_content.empty() ? web_content : \"No results\");\n\n                g_context = new_context;\n\n                // Return question for re-entering decision node\n                nlohmann::json output_json = nlohmann::json::array();\n                output_json.push_back({{\"role\", \"user\"}, {\"content\", g_question}});\n                return output_json.dump();\n            });\n\n        // Configure search node's routing (always returns to decision node)\n        route(web_search_node, [&amp;](const std::string &amp;input, const std::string &amp;output) -&gt; std::optional&lt;std::string&gt; {\n            return \"decide\";\n        });\n\n        // Configure answer node\n        chat_node::chat_node_settings s_answer;\n        const auto answer_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_answer);\n        answer_node-&gt;setPreprocessor([&amp;](const std::string &amp;in) -&gt; std::string {\n            nlohmann::json inJson = nlohmann::json::array();\n            inJson.push_back({{\"role\", \"user\"}, {\"content\", in}});\n            return inJson.dump();\n        });\n\n        // Connect nodes\n        nodeflow::chain(decide_node, web_search_node, \"search\");\n        nodeflow::chain(decide_node, answer_node, \"answer\");\n        nodeflow::chain(web_search_node, decide_node, \"decide\");\n\n        // Create workflow and execute\n        auto f = std::make_shared&lt;nodeflow::Flow&gt;();\n        f-&gt;start(decide_node);\n        auto result = f-&gt;runWithInput&lt;std::string, std::string&gt;(question);\n\n        return result;\n    } catch (const std::exception &amp;ex) {\n        HYB_LOG_ERROR(std::string(\"call_tool_impl_cpp exception: \") + ex.what());\n        return R\"({\"ok\":false,\"error\":\"exception\"})\";\n    } catch (...) {\n        HYB_LOG_ERROR(\"call_tool_impl_cpp unknown exception\");\n        return R\"({\"ok\":false,\"error\":\"unknown exception\"})\";\n    }\n}\n\nint main() {\n    // Build input message\n    nlohmann::json inputJson = nlohmann::json::array();\n    inputJson.push_back({\n        {\"role\", \"user\"},\n        {\"content\", \"What is the latest news about artificial intelligence?\"}\n    });\n\n    // Call agent and get response\n    std::string response = call_tool_impl_cpp(inputJson.dump());\n\n    // Output result\n    std::cout &lt;&lt; response &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"2-3%20Application%20Development%20Three%20Node%20Agent/#key-points","title":"Key Points","text":"<ol> <li>Conditional Routing: Use the <code>route</code> function to dynamically select the next node based on node output</li> <li>Loop Workflow: Routing can implement loops between nodes, supporting iterative search</li> <li>Context Management: Use global variables or state objects to manage context information in workflows</li> <li>YAML Parsing: Decision node returns YAML format, needs to be parsed to extract action type and parameters</li> <li>Tool Invocation: Use <code>OneFuncNode</code> to implement custom logic, invoke tools, and process results</li> </ol>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/","title":"Conditional Routing Agent with Tool Node Development Example","text":""},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#overview","title":"Overview","text":"<p>This example demonstrates how to use <code>ToolNode</code> to implement a conditional routing agent. Unlike using <code>OneFuncNode</code> to manually invoke tools, <code>ToolNode</code> provides a more concise and standardized way to invoke tools, especially suitable for scenarios that need to invoke registered tools.</p> <p>Workflow Diagram:</p> <pre><code>Input \u2192 decide_node (Decision) \u2192 [Conditional Routing]\n                                  \u251c\u2500 \"search\" \u2192 web_search_node (ToolNode) \u2192 decide_node (Loop)\n                                  \u2514\u2500 \"answer\" \u2192 answer_node (Generate Answer) \u2192 Output\n</code></pre> <p>Core Features: - Tool Node: Uses <code>ToolNode</code> to encapsulate tool invocation logic, making code more concise - Conditional Routing: Dynamically select the next node based on the decision node's output - Loop Workflow: Supports looping between decision node and search node until sufficient information is obtained - Context Accumulation: Each search result accumulates into the context for subsequent decisions</p> <p>Differences from Using OneFuncNode: - <code>OneFuncNode</code>: Requires manually calling <code>common_tools::tools::call_tool</code>, suitable for scenarios requiring complex custom logic - <code>ToolNode</code>: Automatically handles tool invocation, specifies tool name and parameters through preprocessor function, code is more concise, suitable for directly invoking registered tools</p>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#development-steps","title":"Development Steps","text":""},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#1-register-tools","title":"1. Register Tools","text":"<p>Same as a single node agent, you need to register the required tools first. This example uses the <code>search_web2</code> tool for web search:</p> <pre><code>#include &lt;tools.h&gt;\n#include &lt;web_search.h&gt;\n\ncommon_tools::tools::add_function_call(search_web_tool,\n    R\"({\"type\":\"function\",\"function\":{\"name\":\"search_web2\",\"description\":\"Search the web using keywords to get general information that doesn't change over time, supporting filtering by country, etc. to get web content, titles, and link information\",\"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search query string used to search for relevant information on the web. Keyword combinations should be concise and clear, avoiding redundant information while ensuring they accurately reflect the core needs of the user's question. Keyword combinations should conform to search engine syntax and logical rules\",\"minLength\":1},\"country\":{\"type\":\"string\",\"description\":\"Country name (must be in English) used to limit search results from a specific country\",\"enum\":[\"china\",\"usa\",\"japan\",\"...\"]}},\"required\":[\"query\"]}}})\"\n);\n</code></pre>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#2-configure-decision-node-decide-node","title":"2. Configure Decision Node (Decide Node)","text":"<p>The decision node is responsible for analyzing the current context and deciding the next action (search or answer):</p> <pre><code>chat_node::chat_node_settings s1;\ns1.model = \"gpt-4o-mini\";\ns1.temperature = 0.7;\ns1.top_p = 0.95;\ns1.max_tokens = 2048;\ns1.tool_choice = \"none\"; \nconst auto decide_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s1);\n</code></pre>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#3-configure-decision-node-preprocessing-and-postprocessing","title":"3. Configure Decision Node Preprocessing and Postprocessing","text":""},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#31-set-preprocessor-function","title":"3.1 Set Preprocessor Function","text":"<p>The preprocessor function builds a decision prompt containing the question, existing context, and available actions:</p> <pre><code>decide_node-&gt;setPreprocessor([&amp;](const std::string&amp; in) -&gt; std::string {\n    nlohmann::json inJson = nlohmann::json::parse(in);\n\n    g_question = inJson[0][\"content\"].get&lt;std::string&gt;();\n\n    std::string prompt = build_ws_prompt(g_question, g_context);\n    inJson[0][\"content\"] = prompt;\n    return inJson.dump();\n});\n</code></pre> <p><code>build_ws_prompt</code> function example:</p> <pre><code>static std::string build_ws_prompt(const std::string &amp;question, const std::string &amp;context) {\n    auto now = std::chrono::system_clock::now();\n    const std::string local_time = fmt::format(\"{:%Y-%m-%d %H:%M:%S}\", now);\n\n    return R\"(### CONTEXT\nYou are a research assistant that can search the web.\nQuestion: )\" + question + R\"(\nPrevious Research: )\" + context + R\"(\n\n### ACTION SPACE\n[1] search\nDescription: Look up more information on the web\nParameters:\n    - query (str): What to search for\n\n[2] answer\nDescription: Answer the question with current knowledge\nParameters:\n    - answer (str): Final answer to the question\n\n## NEXT ACTION\nDecide the next action based on the context and available actions.\nReturn your response in this format:\n\n```yaml\nthinking: |\n    &lt;your step-by-step reasoning process&gt;\naction: search OR answer\nreason: |\n    &lt;why you chose this action&gt;\nanswer: |\n    &lt;if action is answer&gt;\nsearch_query: &lt;specific search query if action is search&gt;\n</code></pre> <p>Current time: )\" + local_time; }</p> <pre><code>\n#### 3.2 Set Postprocessor Function\n\nThe postprocessor function parses the YAML-formatted decision result and extracts the action type and parameters:\n\n```c++\ndecide_node-&gt;setPostprocessor([&amp;](const std::string&amp; output) -&gt; std::string {\n    nlohmann::json output_Json = nlohmann::json::parse(output);\n\n    // Extract and clean response content (remove code block markers)\n    std::string cleaned_response = StripFenceRegex(\n        output_Json.back()[\"content\"].get&lt;std::string&gt;());\n\n    // Parse YAML\n    g_yaml_node = YAML::Load(cleaned_response);\n\n    // Check required fields\n    if (!g_yaml_node[\"thinking\"] || !g_yaml_node[\"action\"] || !g_yaml_node[\"reason\"]) {\n        HYB_LOG_WARN(\"Missing required YAML fields\");\n        return \"search\";  // Default to search on error\n    }\n\n    // Return different values based on action type\n    if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"search\") {\n        return g_yaml_node[\"search_query\"].as&lt;std::string&gt;();  // Return search query\n    }\n\n    if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"answer\") {\n        // Build final answer prompt\n        std::string prompt = R\"(### CONTEXT\nBased on the following information, answer the question.\nQuestion: )\" + g_question + R\"(\nResearch: )\" + g_context + R\"(\n\n## YOUR ANSWER:\nProvide a comprehensive answer using the research results.)\";\n        return prompt;\n    }\n\n    return \"search\";  // Default to search\n});\n</code></pre>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#4-configure-conditional-routing","title":"4. Configure Conditional Routing","text":"<p>Use the <code>route</code> function to configure conditional routing for the decision node, selecting the next node based on the postprocessor function's output:</p> <pre><code>route(decide_node, [&amp;](const std::string &amp;input, const std::string &amp;output) -&gt; std::optional&lt;std::string&gt; {\n    if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"search\") {\n        return \"search\";  // Route to search node\n    }\n\n    if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"answer\") {\n        return \"answer\";  // Route to answer node\n    }\n\n    return std::nullopt;  // No matching route\n});\n</code></pre> <p>Parameter Description: - First parameter: Source node (<code>decide_node</code>) - Second parameter: Route function that receives input and output, returns route name (<code>std::optional&lt;std::string&gt;</code>)</p>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#5-configure-tool-node-toolnode","title":"5. Configure Tool Node (ToolNode)","text":"<p>Key Difference: Use <code>ToolNode</code> instead of <code>OneFuncNode</code></p> <p><code>ToolNode</code> is a node type specifically designed for invoking registered tools. It receives tool name and parameters through a preprocessor function and automatically handles tool invocation.</p>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#51-create-toolnode-instance","title":"5.1 Create ToolNode Instance","text":"<pre><code>#include &lt;tool_node.h&gt;\n\nconst auto web_search_node = std::make_shared&lt;tool_node::ToolNode&lt;std::string, std::string&gt;&gt;();\n</code></pre>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#52-set-preprocessor-function","title":"5.2 Set Preprocessor Function","text":"<p>The preprocessor function needs to convert the input to the format expected by <code>ToolNode</code>: a JSON object containing the tool name and parameters.</p> <pre><code>// Need to save query string for postprocessor function to use\nstd::string g_query = \"\";\n\nweb_search_node-&gt;setPreprocessor([&amp;](const std::string&amp; in) -&gt; std::string {\n    // Save search query for postprocessor function to use\n    g_query = in;\n\n    // Build tool parameters JSON\n    nlohmann::json tool_args_json;\n    tool_args_json[\"query\"] = in;  // in is the search query string\n\n    // Build input format required by ToolNode: contains tool name and parameters\n    nlohmann::json tool_input_json;\n    tool_input_json[\"name\"] = \"search_web2\";  // Specify using search_web2 tool\n    tool_input_json[\"arguments\"] = tool_args_json.dump();  // Parameters need to be JSON string\n\n    return tool_input_json.dump();\n});\n</code></pre> <p>ToolNode Input Format Description: - <code>name</code>: Tool name (string), must be a registered tool name - <code>arguments</code>: Tool parameters (JSON string), must be valid JSON format</p> <p>Note: Since the postprocessor function cannot directly access the preprocessor function's input, if you need to use input data in the postprocessor function, you need to save it to an external variable (such as <code>g_query</code>) in the preprocessor function.</p>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#53-set-postprocessor-function","title":"5.3 Set Postprocessor Function","text":"<p>The postprocessor function processes the tool's return result, parsing and formatting search results:</p> <pre><code>web_search_node-&gt;setPostprocessor([&amp;](const std::string&amp; output) -&gt; std::string {\n    nlohmann::json ws_out_json = nlohmann::json::parse(output);\n    std::string web_content;\n\n    try {\n        // Extract actual search results from wrapped JSON\n        if (ws_out_json.contains(\"content\") &amp;&amp; \n            ws_out_json[\"content\"].is_array() &amp;&amp; \n            !ws_out_json[\"content\"].empty()) {\n            const auto &amp;first = ws_out_json[\"content\"][0];\n            if (first.contains(\"type\") &amp;&amp; \n                first[\"type\"].get&lt;std::string&gt;() == \"text\" &amp;&amp; \n                first.contains(\"text\")) {\n                // Parse actual search results again\n                nlohmann::json ws_payload = nlohmann::json::parse(\n                    first[\"text\"].get&lt;std::string&gt;());\n\n                // Extract and format search results\n                if (ws_payload.contains(\"responses\") &amp;&amp; \n                    ws_payload[\"responses\"].is_array()) {\n                    for (const auto &amp;resp : ws_payload[\"responses\"]) {\n                        web_content +=\n                            \"TITLE: \" + resp[\"title\"].get&lt;std::string&gt;() +\n                            \"\\nURL: \" + resp[\"url\"].get&lt;std::string&gt;() +\n                            \"\\nSNIPPET: \" + resp[\"snippet\"].get&lt;std::string&gt;() +\n                            \"\\n\\n\";\n                    }\n                }\n            }\n        }\n    } catch (const std::exception &amp;e) {\n        HYB_LOG_ERROR(\"Failed to parse search results: {}\", e.what());\n    }\n\n    // Accumulate context (using query string saved in preprocessor function)\n    std::string new_context = \n        g_context +\n        \"\\n\\nSEARCH: \" + (!g_query.empty() ? g_query : \"No query\") +\n        \"\\n\\nRESULTS: \\n\" + \n        (!web_content.empty() ? web_content : \"No results\");\n\n    g_context = new_context;\n\n    // Return question for re-entering decision node\n    nlohmann::json output_json = nlohmann::json::array();\n    output_json.push_back({{\"role\", \"user\"}, {\"content\", g_question}});\n    return output_json.dump();\n});\n</code></pre>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#6-configure-tool-node-routing","title":"6. Configure Tool Node Routing","text":"<p>The tool node always returns to the decision node after execution, forming a loop:</p> <pre><code>route(web_search_node, [&amp;](const std::string &amp;input, const std::string &amp;output) -&gt; std::optional&lt;std::string&gt; {\n    return \"decide\";  // Always route back to decision node\n});\n</code></pre>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#7-configure-answer-node-answer-node","title":"7. Configure Answer Node (Answer Node)","text":"<p>The answer node generates the final answer:</p> <pre><code>chat_node::chat_node_settings s_answer;\nconst auto answer_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_answer);\n\nanswer_node-&gt;setPreprocessor([&amp;](const std::string &amp;in) -&gt; std::string {\n    // Convert input to Chat Completion format\n    nlohmann::json inJson = nlohmann::json::array();\n    inJson.push_back({{\"role\", \"user\"}, {\"content\", in}});\n    return inJson.dump();\n});\n</code></pre>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#8-connect-nodes","title":"8. Connect Nodes","text":"<p>Use the <code>chain</code> function to establish connections between nodes:</p> <pre><code>// Decision node to tool node\nnodeflow::chain(decide_node, web_search_node, \"search\");\n\n// Decision node to answer node\nnodeflow::chain(decide_node, answer_node, \"answer\");\n\n// Tool node back to decision node (forms loop)\nnodeflow::chain(web_search_node, decide_node, \"decide\");\n</code></pre>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#9-create-workflow-and-execute","title":"9. Create Workflow and Execute","text":"<pre><code>// Create workflow\nauto f = std::make_shared&lt;nodeflow::Flow&gt;();\n\n// Set start node\nf-&gt;start(decide_node);\n\n// Execute workflow\nauto result = f-&gt;runWithInput&lt;std::string, std::string&gt;(question);\n</code></pre> <p>Execution Flow: 1. Input question enters <code>decide_node</code> 2. <code>decide_node</code> analyzes context and decides to search or answer 3. If search is chosen:    - Route to <code>web_search_node</code> (ToolNode)    - ToolNode automatically invokes <code>search_web2</code> tool    - Search results accumulate into context    - Route back to <code>decide_node</code> (loop) 4. If answer is chosen:    - Route to <code>answer_node</code> to generate final answer    - Return result</p>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#complete-example","title":"Complete Example","text":"<p>The following is a complete conditional routing agent implementation example using ToolNode:</p> <pre><code>#include &lt;chat_node.h&gt;\n#include &lt;log_util.hpp&gt;\n#include &lt;nodeflow.hpp&gt;\n#include &lt;tool_node.h&gt;\n#include &lt;tools.h&gt;\n#include &lt;web_search.h&gt;\n#include &lt;nlohmann/json.hpp&gt;\n#include &lt;yaml-cpp/yaml.h&gt;\n#include &lt;fmt/chrono.h&gt;\n#include &lt;chrono&gt;\n#include &lt;regex&gt;\n#include &lt;iostream&gt;\n\nstd::string StripFenceRegex(std::string s) {\n    s = std::regex_replace(s, std::regex(R\"(^\\s*```[^\\r\\n]*\\r?\\n)\"), \"\");\n    s = std::regex_replace(s, std::regex(R\"((?:\\r?\\n)?\\s*```\\s*$)\"), \"\");\n    return s;\n}\n\nstatic std::string build_ws_prompt(const std::string &amp;question, const std::string &amp;context) {\n    auto now = std::chrono::system_clock::now();\n    const std::string local_time = fmt::format(\"{:%Y-%m-%d %H:%M:%S}\", now);\n\n    return R\"(### CONTEXT\nYou are a research assistant that can search the web.\nQuestion: )\" + question + R\"(\nPrevious Research: )\" + context + R\"(\n\n### ACTION SPACE\n[1] search\nDescription: Look up more information on the web\nParameters:\n    - query (str): What to search for\n\n[2] answer\nDescription: Answer the question with current knowledge\nParameters:\n    - answer (str): Final answer to the question\n\n## NEXT ACTION\nDecide the next action based on the context and available actions.\nReturn your response in this format:\n\n```yaml\nthinking: |\n    &lt;your step-by-step reasoning process&gt;\naction: search OR answer\nreason: |\n    &lt;why you chose this action&gt;\nanswer: |\n    &lt;if action is answer&gt;\nsearch_query: &lt;specific search query if action is search&gt;\n</code></pre> <p>Current time: )\" + local_time; }</p> <p>// Register tools common_tools::tools::add_function_call(search_web_tool,     R\"({\"type\":\"function\",\"function\":{\"name\":\"search_web2\",\"description\":\"Search the web using keywords to get general information that doesn't change over time, supporting filtering by country, etc. to get web content, titles, and link information\",\"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search query string used to search for relevant information on the web. Keyword combinations should be concise and clear, avoiding redundant information while ensuring they accurately reflect the core needs of the user's question. Keyword combinations should conform to search engine syntax and logical rules\",\"minLength\":1},\"country\":{\"type\":\"string\",\"description\":\"Country name (must be in English) used to limit search results from a specific country\",\"enum\":[\"china\",\"usa\",\"japan\",\"...\"]}},\"required\":[\"query\"]}}})\" );</p> <p>std::string call_tool_impl_cpp(const std::string &amp;question) {     try {         // State variables         std::string g_context = \"\";         std::string g_question = \"\";         std::string g_query = \"\";         YAML::Node g_yaml_node = YAML::Node();</p> <pre><code>    // Configure decision node\n    chat_node::chat_node_settings s1;\n    s1.model = \"gpt-4o-mini\";\n    s1.temperature = 0.7;\n    s1.top_p = 0.95;\n    s1.max_tokens = 2048;\n    s1.tool_choice = \"none\";\n    const auto decide_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s1);\n\n    // Set decision node's preprocessor function\n    decide_node-&gt;setPreprocessor([&amp;](const std::string&amp; in) -&gt; std::string {\n        nlohmann::json inJson = nlohmann::json::parse(in);\n        g_question = inJson[0][\"content\"].get&lt;std::string&gt;();\n        std::string prompt = build_ws_prompt(g_question, g_context);\n        inJson[0][\"content\"] = prompt;\n        return inJson.dump();\n    });\n\n    decide_node-&gt;setPostprocessor([&amp;](const std::string&amp; output) -&gt; std::string {\n        nlohmann::json output_Json = nlohmann::json::parse(output);\n        std::string cleaned_response = StripFenceRegex(\n            output_Json.back()[\"content\"].get&lt;std::string&gt;());\n\n        g_yaml_node = YAML::Load(cleaned_response);\n\n        if (!g_yaml_node[\"thinking\"] || !g_yaml_node[\"action\"] || !g_yaml_node[\"reason\"]) {\n            HYB_LOG_WARN(\"Missing required YAML fields\");\n            return \"search\";\n        }\n\n        HYB_LOG_INFO(\"Thinking: {}\", g_yaml_node[\"thinking\"].as&lt;std::string&gt;());\n        HYB_LOG_INFO(\"Action: {}\", g_yaml_node[\"action\"].as&lt;std::string&gt;());\n        HYB_LOG_INFO(\"Reason: {}\", g_yaml_node[\"reason\"].as&lt;std::string&gt;());\n\n        if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"search\") {\n            return g_yaml_node[\"search_query\"].as&lt;std::string&gt;();\n        }\n\n        if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"answer\") {\n            std::string prompt = R\"(### CONTEXT\n</code></pre> <p>Based on the following information, answer the question. Question: )\" + g_question + R\"( Research: )\" + g_context + R\"(</p>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#your-answer","title":"YOUR ANSWER:","text":"<p>Provide a comprehensive answer using the research results.)\";                 return prompt;             }</p> <pre><code>        return \"search\";\n    });\n\n    // Configure decision node's conditional routing\n    route(decide_node, [&amp;](const std::string &amp;input, const std::string &amp;output) -&gt; std::optional&lt;std::string&gt; {\n        if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"search\") {\n            HYB_LOG_INFO(\"Routing to search node\");\n            return \"search\";\n        }\n        if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"answer\") {\n            HYB_LOG_INFO(\"Routing to answer node\");\n            return \"answer\";\n        }\n        return std::nullopt;\n    });\n\n    // Configure tool node (using ToolNode)\n    const auto web_search_node = std::make_shared&lt;tool_node::ToolNode&lt;std::string, std::string&gt;&gt;();\n\n    // Set tool node's preprocessor function\n    web_search_node-&gt;setPreprocessor([&amp;](const std::string&amp; in) -&gt; std::string {\n        // Save search query for postprocessor function to use\n        g_query = in;\n\n        // Build tool parameters JSON\n        nlohmann::json tool_args_json;\n        tool_args_json[\"query\"] = in;  // in is the search query string\n\n        // Build input format required by ToolNode: contains tool name and parameters\n        nlohmann::json tool_input_json;\n        tool_input_json[\"name\"] = \"search_web2\";  // Specify using search_web2 tool\n        tool_input_json[\"arguments\"] = tool_args_json.dump();  // Parameters need to be JSON string\n\n        return tool_input_json.dump();\n    });\n\n    // Set tool node's postprocessor function\n    web_search_node-&gt;setPostprocessor([&amp;](const std::string&amp; output) -&gt; std::string {\n        nlohmann::json ws_out_json = nlohmann::json::parse(output);\n        std::string web_content;\n\n        try {\n            if (ws_out_json.contains(\"content\") &amp;&amp; \n                ws_out_json[\"content\"].is_array() &amp;&amp; \n                !ws_out_json[\"content\"].empty()) {\n                const auto &amp;first = ws_out_json[\"content\"][0];\n                if (first.contains(\"type\") &amp;&amp; \n                    first[\"type\"].get&lt;std::string&gt;() == \"text\" &amp;&amp; \n                    first.contains(\"text\")) {\n                    // Parse actual search results again\n                    nlohmann::json ws_payload = nlohmann::json::parse(\n                        first[\"text\"].get&lt;std::string&gt;());\n                    if (ws_payload.contains(\"responses\") &amp;&amp; \n                        ws_payload[\"responses\"].is_array()) {\n                        for (const auto &amp;resp : ws_payload[\"responses\"]) {\n                            web_content +=\n                                \"TITLE: \" + resp[\"title\"].get&lt;std::string&gt;() +\n                                \"\\nURL: \" + resp[\"url\"].get&lt;std::string&gt;() +\n                                \"\\nSNIPPET: \" + resp[\"snippet\"].get&lt;std::string&gt;() +\n                                \"\\n\\n\";\n                        }\n                    }\n                }\n            }\n        } catch (const std::exception &amp;e) {\n            HYB_LOG_ERROR(\"Failed to parse search results: {}\", e.what());\n        }\n\n        // Accumulate context\n        std::string new_context = \n            g_context +\n            \"\\n\\nSEARCH: \" + (!g_query.empty() ? g_query : \"No query\") +\n            \"\\n\\nRESULTS: \\n\" + \n            (!web_content.empty() ? web_content : \"No results\");\n\n        g_context = new_context;\n\n        // Return question for re-entering decision node\n        nlohmann::json output_json = nlohmann::json::array();\n        output_json.push_back({{\"role\", \"user\"}, {\"content\", g_question}});\n        return output_json.dump();\n    });\n\n    // Configure tool node's routing (always returns to decision node)\n    route(web_search_node, [&amp;](const std::string &amp;input, const std::string &amp;output) -&gt; std::optional&lt;std::string&gt; {\n        return \"decide\";\n    });\n\n    // Configure answer node\n    chat_node::chat_node_settings s_answer;\n    const auto answer_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_answer);\n    answer_node-&gt;setPreprocessor([&amp;](const std::string &amp;in) -&gt; std::string {\n        nlohmann::json inJson = nlohmann::json::array();\n        inJson.push_back({{\"role\", \"user\"}, {\"content\", in}});\n        return inJson.dump();\n    });\n\n    // Connect nodes\n    nodeflow::chain(decide_node, web_search_node, \"search\");\n    nodeflow::chain(decide_node, answer_node, \"answer\");\n    nodeflow::chain(web_search_node, decide_node, \"decide\");\n\n    // Create workflow and execute\n    auto f = std::make_shared&lt;nodeflow::Flow&gt;();\n    f-&gt;start(decide_node);\n    auto result = f-&gt;runWithInput&lt;std::string, std::string&gt;(question);\n\n    return result;\n} catch (const std::exception &amp;ex) {\n    HYB_LOG_ERROR(std::string(\"call_tool_impl_cpp exception: \") + ex.what());\n    return R\"({\"ok\":false,\"error\":\"exception\"})\";\n} catch (...) {\n    HYB_LOG_ERROR(\"call_tool_impl_cpp unknown exception\");\n    return R\"({\"ok\":false,\"error\":\"unknown exception\"})\";\n}\n</code></pre> <p>}</p> <p>int main() {     // Build input message     nlohmann::json inputJson = nlohmann::json::array();     inputJson.push_back({         {\"role\", \"user\"},         {\"content\", \"What is the latest news about artificial intelligence?\"}     });</p> <pre><code>// Call agent and get response\nstd::string response = call_tool_impl_cpp(inputJson.dump());\n\n// Output result\nstd::cout &lt;&lt; response &lt;&lt; std::endl;\n\nreturn 0;\n</code></pre> <p>} ```</p>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#toolnode-vs-onefuncnode-comparison","title":"ToolNode vs OneFuncNode Comparison","text":""},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#advantages-of-using-toolnode","title":"Advantages of Using ToolNode","text":"<ol> <li>More Concise Code: No need to manually call <code>common_tools::tools::call_tool</code>, ToolNode handles it automatically</li> <li>Standardized Interface: Unified tool invocation format, easier to maintain and debug</li> <li>Error Handling: ToolNode has built-in error handling and logging for tool invocation</li> <li>Type Safety: Clear input and output types through template parameters</li> </ol>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#scenarios-for-using-onefuncnode","title":"Scenarios for Using OneFuncNode","text":"<ol> <li>Complex Custom Logic: Need to perform complex data processing before and after tool invocation</li> <li>Multiple Tool Combinations: Need to invoke multiple tools or perform other operations in one node</li> <li>Special Error Handling: Need custom error handling logic</li> </ol>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#selection-recommendations","title":"Selection Recommendations","text":"<ul> <li>Prefer ToolNode: When you only need to invoke a single registered tool</li> <li>Use OneFuncNode: When you need complex custom logic or multiple tool combinations</li> </ul>"},{"location":"2-4%20Application%20Development%20Conditional%20Routing%20Agent%20with%20Tool%20Node/#key-points","title":"Key Points","text":"<ol> <li>ToolNode Input Format: Must contain <code>name</code> (tool name) and <code>arguments</code> (parameters in JSON string format)</li> <li>Preprocessor Function: Convert input to the format expected by ToolNode</li> <li>Postprocessor Function: Process tool return results, usually need to parse JSON and format</li> <li>Conditional Routing: Use the <code>route</code> function to dynamically select the next node based on node output</li> <li>Loop Workflow: Routing can implement loops between nodes, supporting iterative search</li> <li>Context Management: Use global variables or state objects to manage context information in workflows</li> </ol>"},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/","title":"Inja Template Formatting Tutorial","text":""},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#overview","title":"Overview","text":"<p>Inja is a powerful C++ template engine. The HADK framework provides convenient template formatting functionality through the <code>ChatUtils::format_inja</code> function. Using Inja templates, you can easily insert variable values into template strings to achieve dynamic content generation.</p>"},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#basic-usage","title":"Basic Usage","text":""},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#function-signature","title":"Function Signature","text":"<pre><code>std::string ChatUtils::format_inja(\n    const std::string&amp; template_str,\n    const std::unordered_map&lt;std::string, std::any&gt;&amp; variables\n);\n</code></pre> <p>Parameter Description: - <code>template_str</code>: Template string using <code>{{variable_name}}</code> syntax to define placeholders - <code>variables</code>: Variable map, where keys are variable names and values are corresponding variable values (supports multiple types)</p> <p>Return Value: - Formatted string</p>"},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#template-syntax","title":"Template Syntax","text":"<p>Inja templates use double curly braces <code>{{variable_name}}</code> to define placeholders. The template engine replaces placeholders with corresponding variable values.</p>"},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#examples","title":"Examples","text":""},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#example-1-simple-context-formatting","title":"Example 1: Simple Context Formatting","text":"<p>This is the most basic usage, demonstrating how to use string variables for template replacement:</p> <pre><code>#include &lt;chat_utils.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;unordered_map&gt;\n#include &lt;any&gt;\n\nstd::string simple_template = R\"(\nHello, {{name}}!\n\nToday is a {{weather}} {{time}}.\n\nBased on your {{topic}}, I've prepared the following content for you:\n\n{{content}}\n\nI hope this information is helpful!\n)\";\n\nstd::unordered_map&lt;std::string, std::any&gt; simple_variables;\nsimple_variables[\"name\"] = std::string(\"Xiao Ming\");\nsimple_variables[\"weather\"] = std::string(\"sunny\");\nsimple_variables[\"time\"] = std::string(\"morning\");\nsimple_variables[\"topic\"] = std::string(\"study plan\");\nsimple_variables[\"content\"] = std::string(\"1. Complete math homework\\n2. Read English articles\\n3. Review history knowledge\");\n\ntry {\n    std::string formatted_simple = ChatUtils::format_inja(simple_template, simple_variables);\n    std::cout &lt;&lt; formatted_simple &lt;&lt; \"\\n\";\n} catch (const std::exception&amp; e) {\n    std::cerr &lt;&lt; \"Formatting error: \" &lt;&lt; e.what() &lt;&lt; std::endl;\n}\n</code></pre> <p>Output Result:</p> <pre><code>Hello, Xiao Ming!\n\nToday is a sunny morning.\n\nBased on your study plan, I've prepared the following content for you:\n\n1. Complete math homework\n2. Read English articles\n3. Review history knowledge\n\nI hope this information is helpful!\n</code></pre>"},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#example-2-summary-formatting-reference-deepsearchcpp","title":"Example 2: Summary Formatting (Reference: deepsearch.cpp)","text":"<p>This example demonstrates how to build complex prompt templates, suitable for multi-iteration summary scenarios:</p> <pre><code>std::string summary_template = R\"(\nTask\n\nYou need to summarize information around a theme. Theme: `{{topic}}`\n\nWorkflow\n\n1. Carefully read all information, combine with the theme to understand and fully comprehend the context.\n\n2. Select content related to the theme and summarize the selected content.\n\n3. If the theme is question-based, you need to summarize and infer relevant answers, otherwise summarize normally based on the theme.\n\nRequirements\n\n- The word count must not be less than {{min_words}} words, must be as many as possible.\n\n- The summarized content must be from the information provided, you cannot make things up, especially time-related information.\n\n- The summarized content must be comprehensive enough.\n\n- Logical coherence, smooth sentences.\n\n- Provide the final result directly in markdown format.\n\nInformation to Summarize\n\n```{{summary_search}}```\n)\";\n\nstd::unordered_map&lt;std::string, std::any&gt; summary_variables;\nsummary_variables[\"topic\"] = std::string(\"History of Artificial Intelligence Development\");\nsummary_variables[\"min_words\"] = 3500;\n\n// Simulate multi-iteration summary content\nstd::vector&lt;std::string&gt; all_iteration_summary = {\n    \"First search: The concept of artificial intelligence was first proposed by John McCarthy in 1956.\",\n    \"Second search: Deep learning technology made breakthrough progress in the 2010s.\",\n    \"Third search: Large language models such as the GPT series attracted widespread attention in the 2020s.\"\n};\n\n// Connect multiple summaries with separators\nstd::string all_iteration_summary_str;\nfor (size_t i = 0; i &lt; all_iteration_summary.size(); ++i) {\n    all_iteration_summary_str += all_iteration_summary[i];\n    if (i &lt; all_iteration_summary.size() - 1) {\n        all_iteration_summary_str += \"\\n---\\n\";\n    }\n}\nsummary_variables[\"summary_search\"] = all_iteration_summary_str;\n\ntry {\n    std::string formatted_summary = ChatUtils::format_inja(summary_template, summary_variables);\n    std::cout &lt;&lt; formatted_summary &lt;&lt; \"\\n\";\n} catch (const std::exception&amp; e) {\n    std::cerr &lt;&lt; \"Formatting error: \" &lt;&lt; e.what() &lt;&lt; std::endl;\n}\n</code></pre> <p>Output Result:</p> <pre><code>Task\n\nYou need to summarize information around a theme. Theme: `History of Artificial Intelligence Development`\n\nWorkflow\n\n1. Carefully read all information, combine with the theme to understand and fully comprehend the context.\n\n2. Select content related to the theme and summarize the selected content.\n\n3. If the theme is question-based, you need to summarize and infer relevant answers, otherwise summarize normally based on the theme.\n\nRequirements\n\n- The word count must not be less than 3500 words, must be as many as possible.\n\n- The summarized content must be from the information provided, you cannot make things up, especially time-related information.\n\n- The summarized content must be comprehensive enough.\n\n- Logical coherence, smooth sentences.\n\n- Provide the final result directly in markdown format.\n\nInformation to Summarize\n\n```First search: The concept of artificial intelligence was first proposed by John McCarthy in 1956.\n---\nSecond search: Deep learning technology made breakthrough progress in the 2010s.\n---\nThird search: Large language models such as the GPT series attracted widespread attention in the 2020s.```\n</code></pre>"},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#example-3-using-different-types-of-variables","title":"Example 3: Using Different Types of Variables","text":"<p>Inja templates support variables of multiple data types, including strings, integers, floating-point numbers, booleans, and container types:</p> <pre><code>std::string mixed_template = R\"(\nUser Information:\n\n- Name: {{name}}\n- Age: {{age}}\n- VIP Status: {{is_vip}}\n- Points: {{points}}\n- Tags: {{tags}}\n)\";\n\nstd::unordered_map&lt;std::string, std::any&gt; mixed_variables;\nmixed_variables[\"name\"] = std::string(\"Zhang San\");\nmixed_variables[\"age\"] = 28;\nmixed_variables[\"is_vip\"] = true;\nmixed_variables[\"points\"] = 1250.5;\n\nstd::vector&lt;std::string&gt; tags = {\"Active User\", \"Tech Enthusiast\", \"Early User\"};\nmixed_variables[\"tags\"] = tags;\n\ntry {\n    std::string formatted_mixed = ChatUtils::format_inja(mixed_template, mixed_variables);\n    std::cout &lt;&lt; formatted_mixed &lt;&lt; \"\\n\";\n} catch (const std::exception&amp; e) {\n    std::cerr &lt;&lt; \"Formatting error: \" &lt;&lt; e.what() &lt;&lt; std::endl;\n}\n</code></pre> <p>Output Result:</p> <pre><code>User Information:\n\n- Name: Zhang San\n- Age: 28\n- VIP Status: true\n- Points: 1250.5\n- Tags: Active User, Tech Enthusiast, Early User\n</code></pre>"},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#complete-example-program","title":"Complete Example Program","text":"<p>The following is a complete example program demonstrating all three examples:</p> <pre><code>#include &lt;chat_utils.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;unordered_map&gt;\n#include &lt;any&gt;\n\nint main()\n{\n    std::cout &lt;&lt; \"=== Inja Template Formatting Examples === \\n\";\n\n    // Example 1: Simple context formatting\n    std::cout &lt;&lt; \"\u3010Example 1\u3011Simple Context Formatting\\n\";\n    std::string simple_template = R\"(\nHello, {{name}}!\n\nToday is a {{weather}} {{time}}.\n\nBased on your {{topic}}, I've prepared the following content for you:\n\n{{content}}\n\nI hope this information is helpful!\n\n)\";\n\n    std::unordered_map&lt;std::string, std::any&gt; simple_variables;\n    simple_variables[\"name\"] = std::string(\"Xiao Ming\");\n    simple_variables[\"weather\"] = std::string(\"sunny\");\n    simple_variables[\"time\"] = std::string(\"morning\");\n    simple_variables[\"topic\"] = std::string(\"study plan\");\n    simple_variables[\"content\"] = std::string(\"1. Complete math homework\\n2. Read English articles\\n3. Review history knowledge\");\n\n    try {\n        std::string formatted_simple = ChatUtils::format_inja(simple_template, simple_variables);\n        std::cout &lt;&lt; formatted_simple &lt;&lt; \"\\n\";\n    } catch (const std::exception&amp; e) {\n        std::cerr &lt;&lt; \"Formatting error: \" &lt;&lt; e.what() &lt;&lt; std::endl;\n    }\n\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; std::string(50, '-') &lt;&lt; \"\\n\";\n\n    // Example 2: Summary formatting similar to deepsearch.cpp\n    std::cout &lt;&lt; \"\u3010Example 2\u3011Summary Formatting (Reference: deepsearch.cpp)\\n\";\n    std::string summary_template = R\"(\nTask\n\nYou need to summarize information around a theme. Theme: `{{topic}}`\n\nWorkflow\n\n1. Carefully read all information, combine with the theme to understand and fully comprehend the context.\n\n2. Select content related to the theme and summarize the selected content.\n\n3. If the theme is question-based, you need to summarize and infer relevant answers, otherwise summarize normally based on the theme.\n\nRequirements\n\n- The word count must not be less than {{min_words}} words, must be as many as possible.\n\n- The summarized content must be from the information provided, you cannot make things up, especially time-related information.\n\n- The summarized content must be comprehensive enough.\n\n- Logical coherence, smooth sentences.\n\n- Provide the final result directly in markdown format.\n\nInformation to Summarize\n\n```{{summary_search}}```\n\n)\";\n\n    std::unordered_map&lt;std::string, std::any&gt; summary_variables;\n    summary_variables[\"topic\"] = std::string(\"History of Artificial Intelligence Development\");\n    summary_variables[\"min_words\"] = 3500;\n\n    // Simulate multi-iteration summary content\n    std::vector&lt;std::string&gt; all_iteration_summary = {\n        \"First search: The concept of artificial intelligence was first proposed by John McCarthy in 1956.\",\n        \"Second search: Deep learning technology made breakthrough progress in the 2010s.\",\n        \"Third search: Large language models such as the GPT series attracted widespread attention in the 2020s.\"\n    };\n\n    // Connect multiple summaries with separators\n    std::string all_iteration_summary_str;\n    for (size_t i = 0; i &lt; all_iteration_summary.size(); ++i) {\n        all_iteration_summary_str += all_iteration_summary[i];\n        if (i &lt; all_iteration_summary.size() - 1) {\n            all_iteration_summary_str += \"\\n---\\n\";\n        }\n    }\n    summary_variables[\"summary_search\"] = all_iteration_summary_str;\n\n    try {\n        std::string formatted_summary = ChatUtils::format_inja(summary_template, summary_variables);\n        std::cout &lt;&lt; formatted_summary &lt;&lt; \"\\n\";\n    } catch (const std::exception&amp; e) {\n        std::cerr &lt;&lt; \"Formatting error: \" &lt;&lt; e.what() &lt;&lt; std::endl;\n    }\n\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; std::string(50, '-') &lt;&lt; \"\\n\";\n\n    // Example 3: Using different types of variables\n    std::cout &lt;&lt; \"\u3010Example 3\u3011Using Different Types of Variables\\n\";\n    std::string mixed_template = R\"(\nUser Information:\n\n- Name: {{name}}\n- Age: {{age}}\n- VIP Status: {{is_vip}}\n- Points: {{points}}\n- Tags: {{tags}}\n\n)\";\n\n    std::unordered_map&lt;std::string, std::any&gt; mixed_variables;\n    mixed_variables[\"name\"] = std::string(\"Zhang San\");\n    mixed_variables[\"age\"] = 28;\n    mixed_variables[\"is_vip\"] = true;\n    mixed_variables[\"points\"] = 1250.5;\n\n    std::vector&lt;std::string&gt; tags = {\"Active User\", \"Tech Enthusiast\", \"Early User\"};\n    mixed_variables[\"tags\"] = tags;\n\n    try {\n        std::string formatted_mixed = ChatUtils::format_inja(mixed_template, mixed_variables);\n        std::cout &lt;&lt; formatted_mixed &lt;&lt; \"\\n\";\n    } catch (const std::exception&amp; e) {\n        std::cerr &lt;&lt; \"Formatting error: \" &lt;&lt; e.what() &lt;&lt; std::endl;\n    }\n\n    std::cout &lt;&lt; \"\\n=== Examples Complete ===\\n\";\n\n    return 0;\n}\n</code></pre>"},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#supported-variable-types","title":"Supported Variable Types","text":"<p>The <code>ChatUtils::format_inja</code> function supports the following variable types:</p> <ul> <li>String (<code>std::string</code>): The most commonly used type, directly replaced in the template</li> <li>Integer (<code>int</code>, <code>long</code>, <code>long long</code>, etc.): Automatically converted to string</li> <li>Floating-point (<code>float</code>, <code>double</code>): Automatically converted to string</li> <li>Boolean (<code>bool</code>): Converted to \"true\" or \"false\"</li> <li>Container Types (<code>std::vector&lt;T&gt;</code>): Automatically converted to comma-separated string</li> </ul>"},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#error-handling","title":"Error Handling","text":"<p>When template formatting fails, the <code>format_inja</code> function throws a <code>std::exception</code> exception. It's recommended to use <code>try-catch</code> blocks to catch exceptions and perform appropriate error handling:</p> <pre><code>try {\n    std::string result = ChatUtils::format_inja(template_str, variables);\n    // Use formatted result\n} catch (const std::exception&amp; e) {\n    std::cerr &lt;&lt; \"Template formatting error: \" &lt;&lt; e.what() &lt;&lt; std::endl;\n    // Handle error situation\n}\n</code></pre>"},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use Raw String Literals: Use <code>R\"(...)\"</code> syntax to define template strings, which preserves newlines and special characters, improving readability</p> </li> <li> <p>Variable Naming Conventions: Use meaningful variable names for easier understanding and maintenance</p> </li> <li> <p>Error Handling: Always use <code>try-catch</code> blocks to catch possible exceptions</p> </li> <li> <p>Template Reuse: Define commonly used templates as constants or functions for easy reuse</p> </li> <li> <p>Type Safety: Ensure variable types match the usage scenarios in templates</p> </li> </ol>"},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#application-scenarios","title":"Application Scenarios","text":"<p>Inja template formatting is commonly used in the HADK framework for the following scenarios:</p> <ul> <li>Prompt Construction: Dynamically build LLM prompts, generating different prompts based on context and task requirements</li> <li>Message Formatting: Format user messages, system messages, etc.</li> <li>Summary Generation: Build multi-iteration summary prompts</li> <li>Tool Invocation Parameters: Dynamically generate parameter descriptions for tool invocations</li> </ul>"},{"location":"2-5%20Application%20Development%20Inja%20Template%20Formatting/#reference-resources","title":"Reference Resources","text":"<ul> <li>Inja Official Documentation</li> <li>HADK Framework Documentation</li> </ul>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/","title":"Context Compression Agent Development Example","text":""},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#overview","title":"Overview","text":"<p>The context compression agent demonstrates how to use HADK's CE Node (Context Engine Node) and Chat Node to build an agent that supports long conversation history. This example implements an intelligent assistant that automatically compresses and manages conversation context, avoiding context window limits through context compression while supporting tool invocation and answer polishing.</p> <p>Workflow Diagram:</p> <pre><code>Input \u2192 ce_node (Context Engine Node) \u2192 generate_node (Generate Answer/Tool Call) \u2192 polish_node (Polish Answer) \u2192 Output\n</code></pre> <p>Core Features: - Context Compression: Uses CE Node to automatically compress long conversation history, avoiding model context window limits - Tool Invocation: Generate Node supports automatic tool invocation (e.g., web search) - Answer Polishing: Polish Node polishes the final answer - Linear Workflow: Simple chain structure, easy to understand and maintain</p>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#development-steps","title":"Development Steps","text":""},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#1-register-tools","title":"1. Register Tools","text":"<p>First, register the required tools. This example registers two search tools: <code>search_news</code> and <code>search_web2</code>:</p> <pre><code>#include &lt;tools.h&gt;\n#include &lt;web_search.h&gt;\n\n// Register tools in initialization function\ncommon_tools::tools::add_function_call(search_news_tool,\n    R\"({\"type\":\"function\",\"function\":{\"name\":\"search_news\",\"description\":\"Search the web using keywords to get the latest, time-sensitive information such as weather and news, supporting filtering by time range, country, etc. to get web content, titles, and link information\",\"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search query string used to search for relevant information on the web. Keyword combinations should be concise and clear, avoiding redundant information while ensuring they accurately reflect the core needs of the user's question. Keyword combinations should conform to search engine syntax and logical rules\",\"minLength\":1},\"time_range\":{\"type\":\"string\",\"description\":\"Time range used to limit search results from a specific time\",\"enum\":[\"day\",\"week\"]},\"country\":{\"type\":\"string\",\"description\":\"Region name (must be in English) used to limit search results from a specific region\",\"enum\":[\"china\",\"usa\",\"japan\",\"...\"]}},\"required\":[\"query\"]}}})\"\n);\n\ncommon_tools::tools::add_function_call(search_web_tool,\n    R\"({\"type\":\"function\",\"function\":{\"name\":\"search_web2\",\"description\":\"Search the web using keywords to get general information that doesn't change over time, supporting filtering by country, etc. to get web content, titles, and link information\",\"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search query string used to search for relevant information on the web. Keyword combinations should be concise and clear, avoiding redundant information while ensuring they accurately reflect the core needs of the user's question. Keyword combinations should conform to search engine syntax and logical rules\",\"minLength\":1},\"country\":{\"type\":\"string\",\"description\":\"Country name (must be in English) used to limit search results from a specific country\",\"enum\":[\"china\",\"usa\",\"japan\",\"...\"]}},\"required\":[\"query\"]}}})\"\n);\n</code></pre>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#2-configure-ce-node-context-engine-node","title":"2. Configure CE Node (Context Engine Node)","text":"<p>CE Node is responsible for compressing and managing conversation history to avoid exceeding model context window limits:</p> <pre><code>#include &lt;ce_node.h&gt;\n#include &lt;hybrid_llm.h&gt;\n\nce_node::ce_node_settings s_ce;\n\n// Configure summarization strategy (recommended for long conversations)\ns_ce.strategy = ContextStrategy::SUMMARIZING;\ns_ce.context_limit = 3; // Compression trigger threshold, number of history turns\ns_ce.keep_last_n_turns = 1; // Number of recent original message turns to keep\ns_ce.tool_trim_limit = 600; // Number of characters to keep for tool results in history messages\ns_ce.summarizer_model = \"gpt-4o-mini\";\ns_ce.summarizer_max_tokens = 400;\n\n// Or use trimming strategy (simple but may lose information)\n// s_ce.strategy = ContextStrategy::TRIMMING;\n// s_ce.max_turns = 3; // Maximum number of history turns to keep\n\nconst auto ce_node = std::make_shared&lt;ce_node::CeNode&lt;std::string, std::string&gt;&gt;(s_ce);\n</code></pre> <p>Parameter Description: - <code>strategy</code>: Context management strategy, <code>SUMMARIZING</code> (summarization) or <code>TRIMMING</code> (trimming) - <code>context_limit</code>: Compression trigger threshold, triggers summarization compression when history turns exceed this value - <code>keep_last_n_turns</code>: Number of recent original message turns to keep, these messages won't be compressed - <code>tool_trim_limit</code>: Number of characters to keep for tool results in history messages - <code>summarizer_model</code>: Model name for summarization - <code>summarizer_max_tokens</code>: Maximum tokens for summarizer model - <code>max_turns</code>: Maximum number of history turns to keep (when using <code>TRIMMING</code> strategy)</p>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#3-configure-ce-node-postprocessing-and-routing","title":"3. Configure CE Node Postprocessing and Routing","text":"<p>Set postprocessor function for logging and configure routing to generate node:</p> <pre><code>route(ce_node, [&amp;](const std::string&amp;, const std::string&amp; output) -&gt; std::optional&lt;std::string&gt; {\n    return \"generate\"; // Always route to generate node\n});\n</code></pre>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#4-configure-generate-node","title":"4. Configure Generate Node","text":"<p>Generate Node is responsible for generating answers and supports automatic tool invocation:</p> <pre><code>#include &lt;chat_node.h&gt;\n\nchat_node::chat_node_settings s_generate;\ns_generate.model = \"gpt-4o-mini\";\ns_generate.temperature = 0.7;\ns_generate.top_p = 0.95;\ns_generate.max_tokens = 4096;\ns_generate.tool_choice = \"auto\"; // Automatically choose whether to invoke tools\ns_generate.tools_json = common_tools::tools::get_all_tools_json(); // Get all registered tools\n\nconst auto generate_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_generate);\n</code></pre> <p>Configuration Notes: - <code>tool_choice = \"auto\"</code>: Allows the model to automatically decide whether to invoke tools - <code>tools_json</code>: Pass in all registered tools, the model can invoke them as needed</p>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#5-configure-generate-node-preprocessing-postprocessing-and-routing","title":"5. Configure Generate Node Preprocessing, Postprocessing, and Routing","text":"<p>Generate Node's preprocessor and postprocessor functions can be used for data transformation and logging:</p> <pre><code>generate_node-&gt;setPreprocessor([](const std::string&amp; in) -&gt; std::string {\n    // Pass input directly without modification\n    // Can also perform data transformation or validation here\n    return in;\n});\n\ngenerate_node-&gt;setPostprocessor([](const std::string&amp; output) -&gt; std::string {\n    // Pass output directly without modification\n    // Can also perform result processing or logging here\n    return output;\n});\n\nroute(generate_node, [&amp;](const std::string&amp;, const std::string&amp; output) -&gt; std::optional&lt;std::string&gt; {\n    return \"polish\"; // Always route to polish node\n});\n</code></pre>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#6-configure-polish-node","title":"6. Configure Polish Node","text":"<p>Polish Node is responsible for polishing the final answer:</p> <pre><code>chat_node::chat_node_settings s_polish;\ns_polish.model = \"gpt-4o-mini\";\ns_polish.temperature = 0.7;\ns_polish.top_p = 0.95;\ns_polish.max_tokens = 4096;\ns_polish.tool_choice = \"none\"; // Polish node doesn't need tool invocation\n\nconst auto polish_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_polish);\n</code></pre>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#7-configure-polish-node-preprocessing-and-postprocessing","title":"7. Configure Polish Node Preprocessing and Postprocessing","text":"<p>Polish Node's preprocessor function builds the polishing prompt:</p> <pre><code>polish_node-&gt;setPreprocessor([](const std::string&amp; in) -&gt; std::string {\n    nlohmann::json inJson = nlohmann::json::parse(in);\n\n    // Extract content of the last message\n    std::string _content = inJson.back()[\"content\"].get&lt;std::string&gt;();\n\n    // Build polishing prompt\n    std::string prompt = R\"(### CONTEXT\npolish the following content:\nContent: )\" + _content + R\"(\n## YOUR ANSWER:\nProvide a comprehensive answer using the content.)\";\n\n    // Replace content of the last message\n    inJson.back()[\"content\"] = prompt;\n\n    return inJson.dump();\n});\n\n</code></pre>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#8-connect-nodes","title":"8. Connect Nodes","text":"<p>Use the <code>chain</code> function to establish chain connections between nodes:</p> <pre><code>#include &lt;nodeflow.hpp&gt;\n\n// CE Node to Generate Node\nchain(ce_node, generate_node, \"generate\");\n\n// Generate Node to Polish Node\nchain(generate_node, polish_node, \"polish\");\n</code></pre>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#9-create-workflow-and-execute","title":"9. Create Workflow and Execute","text":"<p>Create workflow, set start node and execute:</p> <pre><code>// Create workflow\nauto f = std::make_shared&lt;nodeflow::Flow&gt;();\n\n// Set start node to CE Node\nf-&gt;start(ce_node);\n\n// Execute workflow\nauto result = f-&gt;runWithInput&lt;std::string, std::string&gt;(message);\n</code></pre> <p>Execution Flow: 1. Input message enters <code>ce_node</code> for context compression processing 2. Compressed context is passed to <code>generate_node</code> 3. <code>generate_node</code> generates answer based on context, invoking tools (e.g., search) when necessary 4. Generated result is passed to <code>polish_node</code> for polishing 5. Return final polished answer</p>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#complete-example","title":"Complete Example","text":"<p>The following is a complete context compression agent implementation example:</p> <pre><code>#include \"hybrid_agents.h\"\n#include &lt;chat_node.h&gt;\n#include &lt;ce_node.h&gt;\n#include &lt;hybrid_llm.h&gt;\n#include &lt;log_util.hpp&gt;\n#include &lt;nodeflow.hpp&gt;\n#include &lt;tools.h&gt;\n#include &lt;web_search.h&gt;\n#include &lt;nlohmann/json.hpp&gt;\n\nnamespace\n{\n    // Lazy initialization function\n    void ensure_initialized()\n    {\n        static bool initialized = []() -&gt; bool\n        {\n            try\n            {\n                HYB_LOG_DEBUG(\"===== hybrid_agent lazy initialization start =====\");\n\n                // Register default local tools\n                HYB_LOG_DEBUG(\"\ud83d\udd27 Register default tools\");\n                common_tools::tools::add_function_call(search_news_tool,\n                    R\"({\"type\":\"function\",\"function\":{\"name\":\"search_news\",\"description\":\"Search the web using keywords to get the latest, time-sensitive information such as weather and news, supporting filtering by time range, country, etc. to get web content, titles, and link information\",\"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search query string used to search for relevant information on the web. Keyword combinations should be concise and clear, avoiding redundant information while ensuring they accurately reflect the core needs of the user's question. Keyword combinations should conform to search engine syntax and logical rules\",\"minLength\":1},\"time_range\":{\"type\":\"string\",\"description\":\"Time range used to limit search results from a specific time\",\"enum\":[\"day\",\"week\"]},\"country\":{\"type\":\"string\",\"description\":\"Region name (must be in English) used to limit search results from a specific region\",\"enum\":[\"china\",\"usa\",\"japan\",\"...\"]}},\"required\":[\"query\"]}}})\"\n                );\n                common_tools::tools::add_function_call(search_web_tool,\n                    R\"({\"type\":\"function\",\"function\":{\"name\":\"search_web2\",\"description\":\"Search the web using keywords to get general information that doesn't change over time, supporting filtering by country, etc. to get web content, titles, and link information\",\"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search query string used to search for relevant information on the web. Keyword combinations should be concise and clear, avoiding redundant information while ensuring they accurately reflect the core needs of the user's question. Keyword combinations should conform to search engine syntax and logical rules\",\"minLength\":1},\"country\":{\"type\":\"string\",\"description\":\"Country name (must be in English) used to limit search results from a specific country\",\"enum\":[\"china\",\"usa\",\"japan\",\"...\"]}},\"required\":[\"query\"]}}})\"\n                );\n\n                HYB_LOG_DEBUG(\"\u2705 hybrid_agent lazy initialization complete\");\n                return true;\n            }\n            catch (const std::exception&amp; ex)\n            {\n                HYB_LOG_ERROR(std::string(\"hybrid_agent ensure_initialized exception: \") + ex.what());\n                return false;\n            }\n        }();\n        (void)initialized;\n    }\n\n    // Bridge function between C and C++\n    std::string call_tool_impl_cpp(const std::string&amp; message)\n    {\n        try\n        {\n            HYB_LOG_INFO(\"===== call_tool_impl_cpp BEGIN =====\");\n\n            auto f = std::make_shared&lt;nodeflow::Flow&gt;();\n\n            // Configure CE Node\n            ce_node::ce_node_settings s_ce;\n            s_ce.strategy = ContextStrategy::SUMMARIZING;\n            s_ce.context_limit = 3; // Compression trigger threshold, number of history turns\n            s_ce.keep_last_n_turns = 1; // Number of recent original message turns to keep\n            s_ce.tool_trim_limit = 600; // Number of characters to keep for tool results in history messages\n            s_ce.summarizer_model = \"gpt-4o-mini\";\n            s_ce.summarizer_max_tokens = 400;\n\n            const auto ce_node = std::make_shared&lt;ce_node::CeNode&lt;std::string, std::string&gt;&gt;(s_ce);\n\n            ce_node-&gt;setPostprocessor([](const std::string&amp; output) -&gt; std::string {\n                HYB_LOG_INFO(\"\ud83e\udd22 ce_node output: {}\", output);\n                return output;\n            });\n\n            route(ce_node, [&amp;](const std::string&amp;, const std::string&amp; output) -&gt; std::optional&lt;std::string&gt; {\n                return \"generate\";\n            });\n\n            // Configure Generate Node\n            chat_node::chat_node_settings s_generate;\n            s_generate.model = \"gpt-4o-mini\";\n            s_generate.temperature = 0.7;\n            s_generate.top_p = 0.95;\n            s_generate.max_tokens = 4096;\n            s_generate.tool_choice = \"auto\";\n            s_generate.tools_json = common_tools::tools::get_all_tools_json();\n\n            const auto generate_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_generate);\n\n            generate_node-&gt;setPreprocessor([](const std::string&amp; in) -&gt; std::string {\n                return in;\n            });\n\n            generate_node-&gt;setPostprocessor([](const std::string&amp; output) -&gt; std::string {\n                return output;\n            });\n\n            route(generate_node, [&amp;](const std::string&amp;, const std::string&amp; output) -&gt; std::optional&lt;std::string&gt; {\n                return \"polish\";\n            });\n\n            // Configure Polish Node\n            chat_node::chat_node_settings s_polish;\n            s_polish.model = \"gpt-4o-mini\";\n            s_polish.temperature = 0.7;\n            s_polish.top_p = 0.95;\n            s_polish.max_tokens = 4096;\n            s_polish.tool_choice = \"none\";\n\n            const auto polish_node = std::make_shared&lt;chat_node::ChatNode&lt;std::string, std::string&gt;&gt;(s_polish);\n\n            polish_node-&gt;setPreprocessor([](const std::string&amp; in) -&gt; std::string {\n                nlohmann::json inJson = nlohmann::json::parse(in);\n                std::string _content = inJson.back()[\"content\"].get&lt;std::string&gt;();\n                std::string prompt = R\"(### CONTEXT\npolish the following content:\nContent: )\" + _content + R\"(\n## YOUR ANSWER:\nProvide a comprehensive answer using the content.)\";\n\n                inJson.back()[\"content\"] = prompt;\n                return inJson.dump();\n            });\n\n            polish_node-&gt;setPostprocessor([](const std::string&amp; output) -&gt; std::string {\n                return output;\n            });\n\n            // Connect nodes\n            chain(ce_node, generate_node, \"generate\");\n            chain(generate_node, polish_node, \"polish\");\n\n            // Create workflow and execute\n            f-&gt;start(ce_node);\n            auto result = f-&gt;runWithInput&lt;std::string, std::string&gt;(message);\n\n            return result;\n        }\n        catch (const std::exception&amp; ex)\n        {\n            HYB_LOG_ERROR(std::string(\"call_tool_impl_cpp exception: \") + ex.what());\n            return {R\"({\"ok\":false,\"error\":\"exception\"})\"};\n        }\n        catch (...)\n        {\n            HYB_LOG_ERROR(\"call_tool_impl_cpp unknown exception\");\n            return {R\"({\"ok\":false,\"error\":\"unknown exception\"})\"};\n        }\n    }\n}\n\nHYBRID_AGENT_API const char* hybrid_agents(const char* input)\n{\n    try\n    {\n        ensure_initialized();\n\n        thread_local std::string tls_result;\n        const std::string message = input ? std::string(input) : std::string();\n\n        tls_result = call_tool_impl_cpp(message);\n        return tls_result.c_str();\n    }\n    catch (...)\n    {\n        static constexpr char k_empty[] = \"{}\";\n        return k_empty;\n    }\n}\n</code></pre>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#key-points","title":"Key Points","text":"<ol> <li>Context Compression: CE Node automatically manages long conversation history, using summarization strategy to compress old messages, avoiding model context window limits</li> <li>Tool Invocation: Generate Node configured with <code>tool_choice = \"auto\"</code>, allowing the model to automatically invoke registered tools as needed</li> <li>Linear Workflow: Use <code>chain</code> function to establish simple chain connections, workflow is clear and easy to understand</li> <li>Answer Polishing: Polish Node polishes generated results to improve answer quality</li> <li>Routing Configuration: Although the workflow is linear, you still need to use <code>route</code> function to configure routing, ensuring data is correctly passed</li> </ol>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#use-cases","title":"Use Cases","text":"<p>This example is suitable for the following scenarios: - Intelligent assistants that need to support long conversation history - Applications that need automatic tool invocation (e.g., search) - Scenarios requiring high-quality answer output - Simple, maintainable workflow structures</p>"},{"location":"2-6%20Application%20Development%20Agent%20via%20CE%20Node/#differences-from-conditional-routing-agent","title":"Differences from Conditional Routing Agent","text":"Feature Context Compression Agent Conditional Routing Agent Workflow Structure Linear chain Conditional routing with loops Context Management CE Node automatic compression Manual context management Tool Invocation Generate Node automatic invocation Custom node manual invocation Complexity Simple Medium Use Cases Long conversations, automatic tool invocation Scenarios requiring decision-making and loops"},{"location":"6%20Basic%20Concepts%20Route/","title":"Route","text":"<p>The routing mechanism is used to dynamically determine the execution path of a workflow based on node input and output. Through the <code>route</code> function combined with the <code>chain</code> function, conditional branching and loop control can be implemented.</p>"},{"location":"6%20Basic%20Concepts%20Route/#route-function","title":"Route Function","text":"<p>Each node supports setting routing logic through the <code>route</code> function. The route function is implemented based on Lambda expressions, receiving the node's input and output as parameters, and returning the action identifier for the next step.</p>"},{"location":"6%20Basic%20Concepts%20Route/#function-signature","title":"Function Signature","text":"<pre><code>template &lt;typename Node, typename Selector&gt;\nvoid route(\n    const std::shared_ptr&lt;Node&gt;&amp; node, \n    Selector selector\n);\n</code></pre> <p>Parameter Description: - <code>node</code>: The node to set routing for - <code>selector</code>: Route selector function, type is <code>std::function&lt;std::optional&lt;std::string&gt;(const IN&amp;, const OUT&amp;)&gt;</code></p> <p>Return Value: - <code>std::optional&lt;std::string&gt;</code>: Returns an action string representing the next execution path, returns <code>std::nullopt</code> to use the default connection</p>"},{"location":"6%20Basic%20Concepts%20Route/#example-1-routing-based-on-decision-results","title":"Example 1: Routing Based on Decision Results","text":"<pre><code>route(decide_node, [&amp;](const std::string&amp; input, const std::string&amp; output) -&gt; std::optional&lt;std::string&gt; {\n    // Parse decision information from output\n    if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"search\") {\n        return \"search\";  // Route to search node\n    }\n    if (g_yaml_node[\"action\"].as&lt;std::string&gt;() == \"answer\") {\n        return \"answer\";  // Route to answer node\n    }\n    return std::nullopt;  // Use default route\n});\n</code></pre>"},{"location":"6%20Basic%20Concepts%20Route/#example-2-routing-based-on-validation-results","title":"Example 2: Routing Based on Validation Results","text":"<pre><code>route(supervisor_node, [&amp;](const std::string&amp; input, const std::string&amp; output) -&gt; std::optional&lt;std::string&gt; {\n    if (g_validation_result.valid) {\n        return \"done\";   // Validation passed, route to completion node\n    } else {\n        return \"retry\"; // Validation failed, route to retry node\n    }\n});\n</code></pre>"}]}