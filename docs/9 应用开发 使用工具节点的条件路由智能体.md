# 使用工具节点的条件路由智能体开发示例

## 概述

本示例展示如何使用 `ToolNode` 实现条件路由智能体。与使用 `OneFuncNode` 手动调用工具的方式不同，`ToolNode` 提供了更简洁、更标准化的工具调用方式，特别适合需要调用已注册工具的场景。

**工作流示意图：**
```
输入 → decide_node（决策） → [条件路由]
                              ├─ "search" → web_search_node（ToolNode 工具节点） → decide_node（循环）
                              └─ "answer" → answer_node（生成答案） → 输出
```

**核心特性：**
- **工具节点**：使用 `ToolNode` 封装工具调用逻辑，代码更简洁
- **条件路由**：根据决策节点的输出动态选择下一个节点
- **循环工作流**：支持在决策节点和搜索节点之间循环，直到获得足够信息
- **上下文累积**：每次搜索的结果会累积到上下文中，供后续决策使用

**与使用 OneFuncNode 的区别：**
- `OneFuncNode`：需要手动调用 `common_tools::tools::call_tool`，适合需要复杂自定义逻辑的场景
- `ToolNode`：自动处理工具调用，通过预处理函数指定工具名称和参数，代码更简洁，适合直接调用已注册工具的场景

## 开发步骤

### 1. 注册工具

与单节点智能体相同，需要先注册所需的工具。本示例使用 `search_web2` 工具进行网络搜索：

```c++
#include <tools.h>
#include <web_search.h>

common_tools::tools::add_function_call(search_web_tool,
    R"({"type":"function","function":{"name":"search_web2","description":"使用关键词搜索网页，用于获取通用的，不会随着时间变化而改变的信息，支持按国家等过滤条件获取网页内容、标题和链接信息","parameters":{"type":"object","properties":{"query":{"type":"string","description":"搜索查询字符串，用于在网络上搜索相关信息。关键词组合应简洁明了，避免冗余信息，同时确保能够准确反映用户问题的核心需求。关键词组合应符合搜索引擎的语法和逻辑规则","minLength":1},"country":{"type":"string","description":"国家名称(必须是英文)，用于限定搜索结果来自的国家","enum":["china","usa","japan","..."]}},"required":["query"]}}})"
);
```

### 2. 配置决策节点（Decide Node）

决策节点负责分析当前上下文，决定下一步行动（搜索或回答）：

```c++
chat_node::chat_node_settings s1;
s1.model = "gpt-4o-mini";
s1.temperature = 0.7;
s1.top_p = 0.95;
s1.max_tokens = 2048;
s1.tool_choice = "none"; 
const auto decide_node = std::make_shared<chat_node::ChatNode<std::string, std::string>>(s1);
```

### 3. 配置决策节点的预处理和后处理

#### 3.1 设置预处理函数

预处理函数构建决策提示词，包含问题、已有上下文和可执行的操作：

```c++
decide_node->setPreprocessor([&](const std::string& in) -> std::string {
    nlohmann::json inJson = nlohmann::json::parse(in);
    
    g_question = inJson[0]["content"].get<std::string>();
    
    std::string prompt = build_ws_prompt(g_question, g_context);
    inJson[0]["content"] = prompt;
    return inJson.dump();
});
```

`build_ws_prompt` 函数示例：

```c++
static std::string build_ws_prompt(const std::string &question, const std::string &context) {
    auto now = std::chrono::system_clock::now();
    const std::string local_time = fmt::format("{:%Y-%m-%d %H:%M:%S}", now);
    
    return R"(### CONTEXT
You are a research assistant that can search the web.
Question: )" + question + R"(
Previous Research: )" + context + R"(

### ACTION SPACE
[1] search
Description: Look up more information on the web
Parameters:
    - query (str): What to search for

[2] answer
Description: Answer the question with current knowledge
Parameters:
    - answer (str): Final answer to the question

## NEXT ACTION
Decide the next action based on the context and available actions.
Return your response in this format:

```yaml
thinking: |
    <your step-by-step reasoning process>
action: search OR answer
reason: |
    <why you chose this action>
answer: |
    <if action is answer>
search_query: <specific search query if action is search>
```
Current time: )" + local_time;
}
```

#### 3.2 设置后处理函数

后处理函数解析 YAML 格式的决策结果，提取行动类型和参数：

```c++
decide_node->setPostprocessor([&](const std::string& output) -> std::string {
    nlohmann::json output_Json = nlohmann::json::parse(output);
    
    // 提取并清理响应内容（移除代码块标记）
    std::string cleaned_response = StripFenceRegex(
        output_Json.back()["content"].get<std::string>());
    
    // 解析 YAML
    g_yaml_node = YAML::Load(cleaned_response);
    
    // 检查必要字段
    if (!g_yaml_node["thinking"] || !g_yaml_node["action"] || !g_yaml_node["reason"]) {
        HYB_LOG_WARN("Missing required YAML fields");
        return "search";  // 错误时默认返回搜索
    }
    
    // 根据行动类型返回不同的值
    if (g_yaml_node["action"].as<std::string>() == "search") {
        return g_yaml_node["search_query"].as<std::string>();  // 返回搜索查询
    }
    
    if (g_yaml_node["action"].as<std::string>() == "answer") {
        // 构建最终答案提示词
        std::string prompt = R"(### CONTEXT
Based on the following information, answer the question.
Question: )" + g_question + R"(
Research: )" + g_context + R"(

## YOUR ANSWER:
Provide a comprehensive answer using the research results.)";
        return prompt;
    }
    
    return "search";  // 默认返回搜索
});
```

### 4. 配置条件路由

使用 `route` 函数为决策节点配置条件路由，根据后处理函数的输出选择下一个节点：

```c++
route(decide_node, [&](const std::string &input, const std::string &output) -> std::optional<std::string> {
    if (g_yaml_node["action"].as<std::string>() == "search") {
        return "search";  // 路由到搜索节点
    }
    
    if (g_yaml_node["action"].as<std::string>() == "answer") {
        return "answer";  // 路由到回答节点
    }
    
    return std::nullopt;  // 无匹配路由
});
```

**参数说明：**
- 第一个参数：源节点（`decide_node`）
- 第二个参数：路由函数，接收输入和输出，返回路由名称（`std::optional<std::string>`）

### 5. 配置工具节点（ToolNode）

**关键区别：使用 `ToolNode` 而不是 `OneFuncNode`**

`ToolNode` 是专门用于调用已注册工具的节点类型，它通过预处理函数接收工具名称和参数，自动处理工具调用。

#### 5.1 创建 ToolNode 实例

```c++
#include <tool_node.h>

const auto web_search_node = std::make_shared<tool_node::ToolNode<std::string, std::string>>();
```

#### 5.2 设置预处理函数

预处理函数需要将输入转换为 `ToolNode` 期望的格式：包含工具名称和参数的 JSON 对象。

```c++
// 需要保存查询字符串供后处理函数使用
std::string g_query = "";

web_search_node->setPreprocessor([&](const std::string& in) -> std::string {
    // 保存搜索查询，供后处理函数使用
    g_query = in;
    
    // 构建工具参数 JSON
    nlohmann::json tool_args_json;
    tool_args_json["query"] = in;  // in 是搜索查询字符串
    
    // 构建 ToolNode 需要的输入格式：包含工具名称和参数
    nlohmann::json tool_input_json;
    tool_input_json["name"] = "search_web2";  // 指定使用 search_web2 工具
    tool_input_json["arguments"] = tool_args_json.dump();  // 参数需要是 JSON 字符串
    
    return tool_input_json.dump();
});
```

**ToolNode 输入格式说明：**
- `name`：工具名称（字符串），必须是已注册的工具名称
- `arguments`：工具参数（JSON 字符串），需要是有效的 JSON 格式

**注意**：由于后处理函数无法直接访问预处理函数的输入，如果需要在后处理函数中使用输入数据，需要在预处理函数中将其保存到外部变量（如 `g_query`）。

#### 5.3 设置后处理函数

后处理函数处理工具返回的结果，解析并格式化搜索结果：

```c++
web_search_node->setPostprocessor([&](const std::string& output) -> std::string {
    nlohmann::json ws_out_json = nlohmann::json::parse(output);
    std::string web_content;
    
    try {
        // 从包装的 JSON 中提取实际搜索结果
        if (ws_out_json.contains("content") && 
            ws_out_json["content"].is_array() && 
            !ws_out_json["content"].empty()) {
            const auto &first = ws_out_json["content"][0];
            if (first.contains("type") && 
                first["type"].get<std::string>() == "text" && 
                first.contains("text")) {
                // 二次解析实际搜索结果
                nlohmann::json ws_payload = nlohmann::json::parse(
                    first["text"].get<std::string>());
                
                // 提取搜索结果并格式化
                if (ws_payload.contains("responses") && 
                    ws_payload["responses"].is_array()) {
                    for (const auto &resp : ws_payload["responses"]) {
                        web_content +=
                            "TITLE: " + resp["title"].get<std::string>() +
                            "\nURL: " + resp["url"].get<std::string>() +
                            "\nSNIPPET: " + resp["snippet"].get<std::string>() +
                            "\n\n";
                    }
                }
            }
        }
    } catch (const std::exception &e) {
        HYB_LOG_ERROR("解析搜索结果失败: {}", e.what());
    }
    
    // 累积上下文（使用预处理函数中保存的查询字符串）
    std::string new_context = 
        g_context +
        "\n\nSEARCH: " + (!g_query.empty() ? g_query : "No query") +
        "\n\nRESULTS: \n" + 
        (!web_content.empty() ? web_content : "No results");
    
    g_context = new_context;
    
    // 返回问题，用于重新进入决策节点
    nlohmann::json output_json = nlohmann::json::array();
    output_json.push_back({{"role", "user"}, {"content", g_question}});
    return output_json.dump();
});
```

### 6. 配置工具节点的路由

工具节点执行后总是返回到决策节点，形成循环：

```c++
route(web_search_node, [&](const std::string &input, const std::string &output) -> std::optional<std::string> {
    return "decide";  // 总是路由回决策节点
});
```

### 7. 配置回答节点（Answer Node）

回答节点生成最终答案：

```c++
chat_node::chat_node_settings s_answer;
const auto answer_node = std::make_shared<chat_node::ChatNode<std::string, std::string>>(s_answer);

answer_node->setPreprocessor([&](const std::string &in) -> std::string {
    // 将输入转换为 Chat Completion 格式
    nlohmann::json inJson = nlohmann::json::array();
    inJson.push_back({{"role", "user"}, {"content", in}});
    return inJson.dump();
});
```

### 8. 连接节点

使用 `chain` 函数建立节点之间的连接：

```c++
// 决策节点到工具节点
nodeflow::chain(decide_node, web_search_node, "search");

// 决策节点到回答节点
nodeflow::chain(decide_node, answer_node, "answer");

// 工具节点回到决策节点（形成循环）
nodeflow::chain(web_search_node, decide_node, "decide");
```

### 9. 创建工作流并执行

```c++
// 创建工作流
auto f = std::make_shared<nodeflow::Flow>();

// 设置起始节点
f->start(decide_node);

// 执行工作流
auto result = f->runWithInput<std::string, std::string>(question);
```

**执行流程：**
1. 输入问题进入 `decide_node`
2. `decide_node` 分析上下文，决定搜索或回答
3. 如果选择搜索：
   - 路由到 `web_search_node`（ToolNode）
   - ToolNode 自动调用 `search_web2` 工具
   - 搜索结果累积到上下文
   - 路由回 `decide_node`（循环）
4. 如果选择回答：
   - 路由到 `answer_node` 生成最终答案
   - 返回结果

## 完整示例

以下是一个完整的使用 ToolNode 的条件路由智能体实现示例：

```c++
#include <chat_node.h>
#include <log_util.hpp>
#include <nodeflow.hpp>
#include <tool_node.h>
#include <tools.h>
#include <web_search.h>
#include <nlohmann/json.hpp>
#include <yaml-cpp/yaml.h>
#include <fmt/chrono.h>
#include <chrono>
#include <regex>
#include <iostream>

std::string StripFenceRegex(std::string s) {
    s = std::regex_replace(s, std::regex(R"(^\s*```[^\r\n]*\r?\n)"), "");
    s = std::regex_replace(s, std::regex(R"((?:\r?\n)?\s*```\s*$)"), "");
    return s;
}

static std::string build_ws_prompt(const std::string &question, const std::string &context) {
    auto now = std::chrono::system_clock::now();
    const std::string local_time = fmt::format("{:%Y-%m-%d %H:%M:%S}", now);
    
    return R"(### CONTEXT
You are a research assistant that can search the web.
Question: )" + question + R"(
Previous Research: )" + context + R"(

### ACTION SPACE
[1] search
Description: Look up more information on the web
Parameters:
    - query (str): What to search for

[2] answer
Description: Answer the question with current knowledge
Parameters:
    - answer (str): Final answer to the question

## NEXT ACTION
Decide the next action based on the context and available actions.
Return your response in this format:

```yaml
thinking: |
    <your step-by-step reasoning process>
action: search OR answer
reason: |
    <why you chose this action>
answer: |
    <if action is answer>
search_query: <specific search query if action is search>
```
Current time: )" + local_time;
}

// 注册工具
common_tools::tools::add_function_call(search_web_tool,
    R"({"type":"function","function":{"name":"search_web2","description":"使用关键词搜索网页，用于获取通用的，不会随着时间变化而改变的信息，支持按国家等过滤条件获取网页内容、标题和链接信息","parameters":{"type":"object","properties":{"query":{"type":"string","description":"搜索查询字符串，用于在网络上搜索相关信息。关键词组合应简洁明了，避免冗余信息，同时确保能够准确反映用户问题的核心需求。关键词组合应符合搜索引擎的语法和逻辑规则","minLength":1},"country":{"type":"string","description":"国家名称(必须是英文)，用于限定搜索结果来自的国家","enum":["china","usa","japan","..."]}},"required":["query"]}}})"
);

std::string call_tool_impl_cpp(const std::string &question) {
    try {
        // 状态变量
        std::string g_context = "";
        std::string g_question = "";
        std::string g_query = "";
        YAML::Node g_yaml_node = YAML::Node();

        // 配置决策节点
        chat_node::chat_node_settings s1;
        s1.model = "gpt-4o-mini";
        s1.temperature = 0.7;
        s1.top_p = 0.95;
        s1.max_tokens = 2048;
        s1.tool_choice = "none";
        const auto decide_node = std::make_shared<chat_node::ChatNode<std::string, std::string>>(s1);

        // 设置决策节点的预处理函数
        decide_node->setPreprocessor([&](const std::string& in) -> std::string {
            nlohmann::json inJson = nlohmann::json::parse(in);
            g_question = inJson[0]["content"].get<std::string>();
            std::string prompt = build_ws_prompt(g_question, g_context);
            inJson[0]["content"] = prompt;
            return inJson.dump();
        });

        decide_node->setPostprocessor([&](const std::string& output) -> std::string {
            nlohmann::json output_Json = nlohmann::json::parse(output);
            std::string cleaned_response = StripFenceRegex(
                output_Json.back()["content"].get<std::string>());

            g_yaml_node = YAML::Load(cleaned_response);

            if (!g_yaml_node["thinking"] || !g_yaml_node["action"] || !g_yaml_node["reason"]) {
                HYB_LOG_WARN("Missing required YAML fields");
                return "search";
            }

            HYB_LOG_INFO("Thinking: {}", g_yaml_node["thinking"].as<std::string>());
            HYB_LOG_INFO("Action: {}", g_yaml_node["action"].as<std::string>());
            HYB_LOG_INFO("Reason: {}", g_yaml_node["reason"].as<std::string>());

            if (g_yaml_node["action"].as<std::string>() == "search") {
                return g_yaml_node["search_query"].as<std::string>();
            }

            if (g_yaml_node["action"].as<std::string>() == "answer") {
                std::string prompt = R"(### CONTEXT
Based on the following information, answer the question.
Question: )" + g_question + R"(
Research: )" + g_context + R"(

## YOUR ANSWER:
Provide a comprehensive answer using the research results.)";
                return prompt;
            }
            
            return "search";
        });

        // 配置决策节点的条件路由
        route(decide_node, [&](const std::string &input, const std::string &output) -> std::optional<std::string> {
            if (g_yaml_node["action"].as<std::string>() == "search") {
                HYB_LOG_INFO("Routing to search node");
                return "search";
            }
            if (g_yaml_node["action"].as<std::string>() == "answer") {
                HYB_LOG_INFO("Routing to answer node");
                return "answer";
            }
            return std::nullopt;
        });

        // 配置工具节点（使用 ToolNode）
        const auto web_search_node = std::make_shared<tool_node::ToolNode<std::string, std::string>>();
        
        // 设置工具节点的预处理函数
        web_search_node->setPreprocessor([&](const std::string& in) -> std::string {
            // 保存搜索查询，供后处理函数使用
            g_query = in;
            
            // 构建工具参数 JSON
            nlohmann::json tool_args_json;
            tool_args_json["query"] = in;  // in 是搜索查询字符串
            
            // 构建 ToolNode 需要的输入格式：包含工具名称和参数
            nlohmann::json tool_input_json;
            tool_input_json["name"] = "search_web2";  // 指定使用 search_web2 工具
            tool_input_json["arguments"] = tool_args_json.dump();  // 参数需要是 JSON 字符串
            
            return tool_input_json.dump();
        });

        // 设置工具节点的后处理函数
        web_search_node->setPostprocessor([&](const std::string& output) -> std::string {
            nlohmann::json ws_out_json = nlohmann::json::parse(output);
            std::string web_content;
            
            try {
                if (ws_out_json.contains("content") && 
                    ws_out_json["content"].is_array() && 
                    !ws_out_json["content"].empty()) {
                    const auto &first = ws_out_json["content"][0];
                    if (first.contains("type") && 
                        first["type"].get<std::string>() == "text" && 
                        first.contains("text")) {
                        // 二次解析实际搜索结果
                        nlohmann::json ws_payload = nlohmann::json::parse(
                            first["text"].get<std::string>());
                        if (ws_payload.contains("responses") && 
                            ws_payload["responses"].is_array()) {
                            for (const auto &resp : ws_payload["responses"]) {
                                web_content +=
                                    "TITLE: " + resp["title"].get<std::string>() +
                                    "\nURL: " + resp["url"].get<std::string>() +
                                    "\nSNIPPET: " + resp["snippet"].get<std::string>() +
                                    "\n\n";
                            }
                        }
                    }
                }
            } catch (const std::exception &e) {
                HYB_LOG_ERROR("解析搜索结果失败: {}", e.what());
            }

            // 累积上下文
            std::string new_context = 
                g_context +
                "\n\nSEARCH: " + (!g_query.empty() ? g_query : "No query") +
                "\n\nRESULTS: \n" + 
                (!web_content.empty() ? web_content : "No results");

            g_context = new_context;

            // 返回问题，用于重新进入决策节点
            nlohmann::json output_json = nlohmann::json::array();
            output_json.push_back({{"role", "user"}, {"content", g_question}});
            return output_json.dump();
        });

        // 配置工具节点的路由（总是返回决策节点）
        route(web_search_node, [&](const std::string &input, const std::string &output) -> std::optional<std::string> {
            return "decide";
        });

        // 配置回答节点
        chat_node::chat_node_settings s_answer;
        const auto answer_node = std::make_shared<chat_node::ChatNode<std::string, std::string>>(s_answer);
        answer_node->setPreprocessor([&](const std::string &in) -> std::string {
            nlohmann::json inJson = nlohmann::json::array();
            inJson.push_back({{"role", "user"}, {"content", in}});
            return inJson.dump();
        });

        // 连接节点
        nodeflow::chain(decide_node, web_search_node, "search");
        nodeflow::chain(decide_node, answer_node, "answer");
        nodeflow::chain(web_search_node, decide_node, "decide");

        // 创建工作流并执行
        auto f = std::make_shared<nodeflow::Flow>();
        f->start(decide_node);
        auto result = f->runWithInput<std::string, std::string>(question);

        return result;
    } catch (const std::exception &ex) {
        HYB_LOG_ERROR(std::string("call_tool_impl_cpp exception: ") + ex.what());
        return R"({"ok":false,"error":"exception"})";
    } catch (...) {
        HYB_LOG_ERROR("call_tool_impl_cpp unknown exception");
        return R"({"ok":false,"error":"unknown exception"})";
    }
}

int main() {
    // 构建输入消息
    nlohmann::json inputJson = nlohmann::json::array();
    inputJson.push_back({
        {"role", "user"},
        {"content", "What is the latest news about artificial intelligence?"}
    });
    
    // 调用智能体并获取响应
    std::string response = call_tool_impl_cpp(inputJson.dump());
    
    // 输出结果
    std::cout << response << std::endl;

    return 0;
}
```

## ToolNode vs OneFuncNode 对比

### 使用 ToolNode 的优势

1. **代码更简洁**：不需要手动调用 `common_tools::tools::call_tool`，ToolNode 自动处理
2. **标准化接口**：统一的工具调用格式，便于维护和调试
3. **错误处理**：ToolNode 内置了工具调用的错误处理和日志记录
4. **类型安全**：通过模板参数明确输入输出类型

### 使用 OneFuncNode 的场景

1. **复杂自定义逻辑**：需要在工具调用前后执行复杂的数据处理
2. **多工具组合**：需要在一个节点中调用多个工具或执行其他操作
3. **特殊错误处理**：需要自定义的错误处理逻辑

### 选择建议

- **优先使用 ToolNode**：当只需要调用单个已注册工具时
- **使用 OneFuncNode**：当需要复杂的自定义逻辑或多工具组合时

## 关键要点

1. **ToolNode 输入格式**：必须包含 `name`（工具名称）和 `arguments`（JSON 字符串格式的参数）
2. **预处理函数**：将输入转换为 ToolNode 期望的格式
3. **后处理函数**：处理工具返回的结果，通常需要解析 JSON 并格式化
4. **条件路由**：使用 `route` 函数根据节点输出动态选择下一个节点
5. **循环工作流**：通过路由可以实现节点之间的循环，支持迭代搜索
6. **上下文管理**：使用全局变量或状态对象管理工作流中的上下文信息

