# 条件路由智能体开发示例

## 概述

条件路由智能体展示了如何使用 HADK 的条件路由（`route`）功能实现复杂的工作流。本示例实现了一个研究助手智能体，能够根据当前上下文动态决定是继续搜索信息还是直接回答问题，支持循环搜索直到获得足够信息。

**工作流示意图：**
```
输入 → decide_node（决策） → [条件路由]
                              ├─ "search" → web_search_node（网络搜索） → decide_node（循环）
                              └─ "answer" → answer_node（生成答案） → 输出
```

**核心特性：**
- 条件路由：根据决策节点的输出动态选择下一个节点
- 循环工作流：支持在决策节点和搜索节点之间循环，直到获得足够信息
- 上下文累积：每次搜索的结果会累积到上下文中，供后续决策使用

## 开发步骤

### 1. 注册工具

与单节点智能体相同，需要先注册所需的工具。本示例使用 `search_web2` 工具进行网络搜索：

```c++
tool_node::tool_node::add_function_call<search_web_tool>(
    R"({"type":"function","function":{"name":"search_web2","description":"使用关键词搜索网页，用于获取通用的，不会随着时间变化而改变的信息","parameters":{"type":"object","properties":{"query":{"type":"string","description":"搜索查询字符串"},"country":{"type":"string","description":"国家名称"}},"required":["query"]}}})"
);
```

### 2. 配置决策节点（Decide Node）

决策节点负责分析当前上下文，决定下一步行动（搜索或回答）：

```c++
chat_node::chat_node_settings s1;
s1.model = "gpt-4o-mini";
s1.temperature = 0.7;
s1.top_p = 0.95;
s1.max_tokens = 2048;
s1.tool_choice = "none"; 
const auto decide_node = std::make_shared<chat_node::EchoChatNode<std::string, std::string>>(s1);
```

### 3. 配置决策节点的预处理和后处理

#### 3.1 设置预处理函数

预处理函数构建决策提示词，包含问题、已有上下文和可执行的操作：

```c++
decide_node->setPreprocessor([&](const std::string& in) -> std::string {
    nlohmann::json inJson = nlohmann::json::parse(in);
    
    g_question = inJson[0]["content"].get<std::string>();
    
    std::string prompt = build_ws_prompt(g_question, g_context);
    inJson[0]["content"] = prompt;
    return inJson.dump();
});
```

`build_ws_prompt` 函数示例：

```c++
static std::string build_ws_prompt(const std::string &question, const std::string &context) {
    auto now = std::chrono::system_clock::now();
    const std::string local_time = fmt::format("{:%Y-%m-%d %H:%M:%S}", now);
    
    return R"(### CONTEXT
You are a research assistant that can search the web.
Question: )" + question + R"(
Previous Research: )" + context + R"(

### ACTION SPACE
[1] search
Description: Look up more information on the web
Parameters:
    - query (str): What to search for

[2] answer
Description: Answer the question with current knowledge
Parameters:
    - answer (str): Final answer to the question

## NEXT ACTION
Decide the next action based on the context and available actions.
Return your response in this format:

```yaml
thinking: |
    <your step-by-step reasoning process>
action: search OR answer
reason: |
    <why you chose this action>
answer: |
    <if action is answer>
search_query: <specific search query if action is search>
```
Current time: )" + local_time;
}
```

#### 3.2 设置后处理函数

后处理函数解析 YAML 格式的决策结果，提取行动类型和参数：

```c++
decide_node->setPostprocessor([&](const std::string& output) -> std::string {
    nlohmann::json output_Json = nlohmann::json::parse(output);
    
    // 提取并清理响应内容（移除代码块标记）
    std::string cleaned_response = StripFenceRegex(
        output_Json.back()["content"].get<std::string>());
    
    // 解析 YAML
    g_yaml_node = YAML::Load(cleaned_response);
    
    // 检查必要字段
    if (!g_yaml_node["thinking"] || !g_yaml_node["action"] || !g_yaml_node["reason"]) {
        HYB_LOG_WARN("Missing required YAML fields");
        return "search";  // 错误时默认返回搜索
    }
    
    // 根据行动类型返回不同的值
    if (g_yaml_node["action"].as<std::string>() == "search") {
        return g_yaml_node["search_query"].as<std::string>();  // 返回搜索查询
    }
    
    if (g_yaml_node["action"].as<std::string>() == "answer") {
        // 构建最终答案提示词
        std::string prompt = R"(### CONTEXT
Based on the following information, answer the question.
Question: )" + g_question + R"(
Research: )" + g_context + R"(

## YOUR ANSWER:
Provide a comprehensive answer using the research results.)";
        return prompt;
    }
    
    return "search";  // 默认返回搜索
});
```

### 4. 配置条件路由

使用 `route` 函数为决策节点配置条件路由，根据后处理函数的输出选择下一个节点：

```c++
route(decide_node, [&](const std::string &input, const std::string &output) -> std::optional<std::string> {
    if (g_yaml_node["action"].as<std::string>() == "search") {
        return "search";  // 路由到搜索节点
    }
    
    if (g_yaml_node["action"].as<std::string>() == "answer") {
        return "answer";  // 路由到回答节点
    }
    
    return std::nullopt;  // 无匹配路由
});
```

**参数说明：**
- 第一个参数：源节点（`decide_node`）
- 第二个参数：路由函数，接收输入和输出，返回路由名称（`std::optional<std::string>`）

### 5. 配置搜索节点（Web Search Node）

搜索节点使用 `OneFuncNode` 实现自定义逻辑，调用工具并处理结果：

```c++
auto web_search_node = std::make_shared<nodeflow::OneFuncNode<std::string, std::string>>(
    [&](const std::string &input) -> std::string {
        // 构建工具调用参数
        nlohmann::json ws_in_json;
        ws_in_json["query"] = input;  // input 是搜索查询字符串
        
        // 调用搜索工具
        std::string ws_out = tool_node::tool_node::call_tool("search_web2", ws_in_json.dump());
        
        // 解析工具返回结果（工具返回的是包装后的 JSON）
        nlohmann::json ws_out_json = nlohmann::json::parse(ws_out);
        
        std::string web_content;
        try {
            // 从包装的 JSON 中提取实际搜索结果
            if (ws_out_json.contains("content") && 
                ws_out_json["content"].is_array() && 
                !ws_out_json["content"].empty()) {
                const auto &first = ws_out_json["content"][0];
                if (first.contains("type") && 
                    first["type"].get<std::string>() == "text" && 
                    first.contains("text")) {
                    // 二次解析实际搜索结果
                    nlohmann::json ws_payload = nlohmann::json::parse(
                        first["text"].get<std::string>());
                    
                    // 提取搜索结果并格式化
                    if (ws_payload.contains("responses") && 
                        ws_payload["responses"].is_array()) {
                        for (const auto &resp : ws_payload["responses"]) {
                            web_content +=
                                "TITLE: " + resp["title"].get<std::string>() +
                                "\nURL: " + resp["url"].get<std::string>() +
                                "\nSNIPPET: " + resp["snippet"].get<std::string>() +
                                "\n\n";
                        }
                    }
                }
            }
        } catch (const std::exception &e) {
            HYB_LOG_ERROR("解析搜索结果失败: {}", e.what());
        }
        
        // 累积上下文
        std::string new_context = 
            g_context +
            "\n\nSEARCH: " + input +
            "\n\nRESULTS: \n" + 
            (!web_content.empty() ? web_content : "No results");
        
        g_context = new_context;
        
        // 返回问题，用于重新进入决策节点
        nlohmann::json output_json = nlohmann::json::array();
        output_json.push_back({{"role", "user"}, {"content", g_question}});
        return output_json.dump();
    });
```

### 6. 配置搜索节点的路由

搜索节点执行后总是返回到决策节点，形成循环：

```c++
route(web_search_node, [&](const std::string &input, const std::string &output) -> std::optional<std::string> {
    return "decide";  // 总是路由回决策节点
});
```

### 7. 配置回答节点（Answer Node）

回答节点生成最终答案：

```c++
chat_node::chat_node_settings s_answer;
const auto answer_node = std::make_shared<chat_node::EchoChatNode<std::string, std::string>>(s_answer);

answer_node->setPreprocessor([&](const std::string &in) -> std::string {
    // 将输入转换为 Chat Completion 格式
    nlohmann::json inJson = nlohmann::json::array();
    inJson.push_back({{"role", "user"}, {"content", in}});
    return inJson.dump();
});
```

### 8. 连接节点

使用 `chain` 函数建立节点之间的连接：

```c++
// 决策节点到搜索节点
nodeflow::chain(decide_node, web_search_node, "search");

// 决策节点到回答节点
nodeflow::chain(decide_node, answer_node, "answer");

// 搜索节点回到决策节点（形成循环）
nodeflow::chain(web_search_node, decide_node, "decide");
```

### 9. 创建工作流并执行

```c++
// 创建工作流
auto f = std::make_shared<nodeflow::Flow>();

// 设置起始节点
f->start(decide_node);

// 执行工作流
auto result = f->runWithInput<std::string, std::string>(question);
```

**执行流程：**
1. 输入问题进入 `decide_node`
2. `decide_node` 分析上下文，决定搜索或回答
3. 如果选择搜索：
   - 路由到 `web_search_node` 执行搜索
   - 搜索结果累积到上下文
   - 路由回 `decide_node`（循环）
4. 如果选择回答：
   - 路由到 `answer_node` 生成最终答案
   - 返回结果

## 完整示例

以下是一个完整的条件路由智能体实现示例：

```c++
#include <chat_node.h>
#include <log_util.hpp>
#include <nodeflow.hpp>
#include <tool_node.h>
#include <web_search.h>
#include <nlohmann/json.hpp>
#include <yaml-cpp/yaml.h>
#include <fmt/chrono.h>
#include <chrono>
#include <regex>
#include <iostream>

std::string StripFenceRegex(std::string s) {
    s = std::regex_replace(s, std::regex(R"(^\s*```[^\r\n]*\r?\n)"), "");
    s = std::regex_replace(s, std::regex(R"((?:\r?\n)?\s*```\s*$)"), "");
    return s;
}

static std::string build_ws_prompt(const std::string &question, const std::string &context) {
    auto now = std::chrono::system_clock::now();
    const std::string local_time = fmt::format("{:%Y-%m-%d %H:%M:%S}", now);
    
    return R"(### CONTEXT
            You are a research assistant that can search the web.
            Question: )" + question + R"(
            Previous Research: )" + context + R"(

            ### ACTION SPACE
            [1] search
            Description: Look up more information on the web
            Parameters:
                - query (str): What to search for

            [2] answer
            Description: Answer the question with current knowledge
            Parameters:
                - answer (str): Final answer to the question

            ## NEXT ACTION
            Decide the next action based on the context and available actions.
            Return your response in this format:

            ```yaml
            thinking: |
                <your step-by-step reasoning process>
            action: search OR answer
            reason: |
                <why you chose this action>
            answer: |
                <if action is answer>
            search_query: <specific search query if action is search>
            ```
Current time: )" + local_time;
}

// 注册工具
tool_node::tool_node::add_function_call<search_web_tool>(
    R"({"type":"function","function":{"name":"search_web2","description":"使用关键词搜索网页","parameters":{"type":"object","properties":{"query":{"type":"string","description":"搜索查询字符串"},"country":{"type":"string","description":"国家名称"}},"required":["query"]}}})"
);

std::string call_tool_impl_cpp(const std::string &question) {
    try {
        // 状态变量
        std::string g_context = "";
        std::string g_question = "";
        YAML::Node g_yaml_node = YAML::Node();

        // 配置决策节点
        chat_node::chat_node_settings s1;
        s1.model = "gpt-4o-mini";
        s1.temperature = 0.7;
        s1.top_p = 0.95;
        s1.max_tokens = 2048;
        s1.tool_choice = "none";
        const auto decide_node = std::make_shared<chat_node::EchoChatNode<std::string, std::string>>(s1);

        // 设置决策节点的预处理函数
        decide_node->setPreprocessor([&](const std::string& in) -> std::string {
            nlohmann::json inJson = nlohmann::json::parse(in);
            g_question = inJson[0]["content"].get<std::string>();
            std::string prompt = build_ws_prompt(g_question, g_context);
            inJson[0]["content"] = prompt;
            return inJson.dump();
        });

        decide_node->setPostprocessor([&](const std::string& output) -> std::string {
            nlohmann::json output_Json = nlohmann::json::parse(output);
            std::string cleaned_response = StripFenceRegex(
                output_Json.back()["content"].get<std::string>());

            g_yaml_node = YAML::Load(cleaned_response);

            if (!g_yaml_node["thinking"] || !g_yaml_node["action"] || !g_yaml_node["reason"]) {
                HYB_LOG_WARN("Missing required YAML fields");
                return "search";
            }

            HYB_LOG_INFO("Thinking: {}", g_yaml_node["thinking"].as<std::string>());
            HYB_LOG_INFO("Action: {}", g_yaml_node["action"].as<std::string>());
            HYB_LOG_INFO("Reason: {}", g_yaml_node["reason"].as<std::string>());

            if (g_yaml_node["action"].as<std::string>() == "search") {
                return g_yaml_node["search_query"].as<std::string>();
            }

            if (g_yaml_node["action"].as<std::string>() == "answer") {
                std::string prompt = R"(### CONTEXT
Based on the following information, answer the question.
Question: )" + g_question + R"(
Research: )" + g_context + R"(

## YOUR ANSWER:
Provide a comprehensive answer using the research results.)";
                return prompt;
            }
            
            return "search";
        });

        // 配置决策节点的条件路由
        route(decide_node, [&](const std::string &input, const std::string &output) -> std::optional<std::string> {
            if (g_yaml_node["action"].as<std::string>() == "search") {
                HYB_LOG_INFO("Routing to search node");
                return "search";
            }
            if (g_yaml_node["action"].as<std::string>() == "answer") {
                HYB_LOG_INFO("Routing to answer node");
                return "answer";
            }
            return std::nullopt;
        });

        // 配置搜索节点
        auto web_search_node = std::make_shared<nodeflow::OneFuncNode<std::string, std::string>>(
            [&](const std::string &input) -> std::string {
                // 构建工具调用参数
                nlohmann::json ws_in_json;
                ws_in_json["query"] = input;

                // 调用搜索工具
                std::string ws_out = tool_node::tool_node::call_tool("search_web2", ws_in_json.dump());
                nlohmann::json ws_out_json = nlohmann::json::parse(ws_out);

                // 解析搜索结果
                std::string web_content;
                try {
                    if (ws_out_json.contains("content") && 
                        ws_out_json["content"].is_array() && 
                        !ws_out_json["content"].empty()) {
                        const auto &first = ws_out_json["content"][0];
                        if (first.contains("type") && 
                            first["type"].get<std::string>() == "text" && 
                            first.contains("text")) {
                            // 二次解析实际搜索结果
                            nlohmann::json ws_payload = nlohmann::json::parse(
                                first["text"].get<std::string>());
                            if (ws_payload.contains("responses") && 
                                ws_payload["responses"].is_array()) {
                                for (const auto &resp : ws_payload["responses"]) {
                                    web_content +=
                                        "TITLE: " + resp["title"].get<std::string>() +
                                        "\nURL: " + resp["url"].get<std::string>() +
                                        "\nSNIPPET: " + resp["snippet"].get<std::string>() +
                                        "\n\n";
                                }
                            }
                        }
                    }
                } catch (const std::exception &e) {
                    HYB_LOG_ERROR("解析搜索结果失败: {}", e.what());
                }

                // 累积上下文
                std::string new_context = 
                    g_context +
                    "\n\nSEARCH: " + input +
                    "\n\nRESULTS: \n" + 
                    (!web_content.empty() ? web_content : "No results");

                g_context = new_context;

                // 返回问题，用于重新进入决策节点
                nlohmann::json output_json = nlohmann::json::array();
                output_json.push_back({{"role", "user"}, {"content", g_question}});
                return output_json.dump();
            });

        // 配置搜索节点的路由（总是返回决策节点）
        route(web_search_node, [&](const std::string &input, const std::string &output) -> std::optional<std::string> {
            return "decide";
        });

        // 配置回答节点
        chat_node::chat_node_settings s_answer;
        const auto answer_node = std::make_shared<chat_node::EchoChatNode<std::string, std::string>>(s_answer);
        answer_node->setPreprocessor([&](const std::string &in) -> std::string {
            nlohmann::json inJson = nlohmann::json::array();
            inJson.push_back({{"role", "user"}, {"content", in}});
            return inJson.dump();
        });

        // 连接节点
        nodeflow::chain(decide_node, web_search_node, "search");
        nodeflow::chain(decide_node, answer_node, "answer");
        nodeflow::chain(web_search_node, decide_node, "decide");

        // 创建工作流并执行
        auto f = std::make_shared<nodeflow::Flow>();
        f->start(decide_node);
        auto result = f->runWithInput<std::string, std::string>(question);

        return result;
    } catch (const std::exception &ex) {
        HYB_LOG_ERROR(std::string("call_tool_impl_cpp exception: ") + ex.what());
        return R"({"ok":false,"error":"exception"})";
    } catch (...) {
        HYB_LOG_ERROR("call_tool_impl_cpp unknown exception");
        return R"({"ok":false,"error":"unknown exception"})";
    }
}

int main() {
    // 构建输入消息
    nlohmann::json inputJson = nlohmann::json::array();
    inputJson.push_back({
        {"role", "user"},
        {"content", "What is the latest news about artificial intelligence?"}
    });
    
    // 调用智能体并获取响应
    std::string response = call_tool_impl_cpp(inputJson.dump());
    
    // 输出结果
    std::cout << response << std::endl;

    return 0;
}
```

## 关键要点

1. **条件路由**：使用 `route` 函数根据节点输出动态选择下一个节点
2. **循环工作流**：通过路由可以实现节点之间的循环，支持迭代搜索
3. **上下文管理**：使用全局变量或状态对象管理工作流中的上下文信息
4. **YAML 解析**：决策节点返回 YAML 格式，需要解析后提取行动类型和参数
5. **工具调用**：使用 `OneFuncNode` 实现自定义逻辑，调用工具并处理结果

